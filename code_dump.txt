# CODE DUMP FROM: /home/delia/Conversational_Robot/Conversational_Bot
# FILE COUNT: 79

# MANIFEST:
/home/delia/Conversational_Robot/Conversational_Bot/README.md
/home/delia/Conversational_Robot/Conversational_Bot/configs/asr.yaml
/home/delia/Conversational_Robot/Conversational_Bot/configs/audio.yaml
/home/delia/Conversational_Robot/Conversational_Bot/configs/core.yaml
/home/delia/Conversational_Robot/Conversational_Bot/configs/llm.yaml
/home/delia/Conversational_Robot/Conversational_Bot/configs/routing.yaml
/home/delia/Conversational_Robot/Conversational_Bot/configs/tts.yaml
/home/delia/Conversational_Robot/Conversational_Bot/configs/wake.yaml
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_100811/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_100811/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_100811/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_104602/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_104602/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_104602/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_110133/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_110133/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_110133/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_111001/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_111001/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_111001/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_112548/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_112548/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_112548/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_114256/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_114256/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_114256/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124004/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124004/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124004/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124030/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124030/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124030/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124210/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124210/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124210/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124352/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124352/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124352/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124425/00_asr.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124425/10_llm_stream.txt
/home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124425/20_spoken_text.txt
/home/delia/Conversational_Robot/Conversational_Bot/requirements.txt
/home/delia/Conversational_Robot/Conversational_Bot/src/__init__.py
/home/delia/Conversational_Robot/Conversational_Bot/src/app.py
/home/delia/Conversational_Robot/Conversational_Bot/src/asr/__init__.py
/home/delia/Conversational_Robot/Conversational_Bot/src/asr/engine_faster.py
/home/delia/Conversational_Robot/Conversational_Bot/src/asr/engine_openai.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/__init__.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/aec_webrtc.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/barge.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/devices.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/input.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/monitors.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/output.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/processing.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/reverse_capture.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/vad.py
/home/delia/Conversational_Robot/Conversational_Bot/src/audio/wake_porcupine.py
/home/delia/Conversational_Robot/Conversational_Bot/src/core/config.py
/home/delia/Conversational_Robot/Conversational_Bot/src/core/config_schema.py
/home/delia/Conversational_Robot/Conversational_Bot/src/core/fast_exit.py
/home/delia/Conversational_Robot/Conversational_Bot/src/core/health.py
/home/delia/Conversational_Robot/Conversational_Bot/src/core/logger.py
/home/delia/Conversational_Robot/Conversational_Bot/src/core/states.py
/home/delia/Conversational_Robot/Conversational_Bot/src/core/wake.py
/home/delia/Conversational_Robot/Conversational_Bot/src/llm/__init__.py
/home/delia/Conversational_Robot/Conversational_Bot/src/llm/engine.py
/home/delia/Conversational_Robot/Conversational_Bot/src/llm/stream_shaper.py
/home/delia/Conversational_Robot/Conversational_Bot/src/telemetry/metrics.py
/home/delia/Conversational_Robot/Conversational_Bot/src/tts/__init__.py
/home/delia/Conversational_Robot/Conversational_Bot/src/tts/engine.py
/home/delia/Conversational_Robot/Conversational_Bot/src/tts/piper_backend.py
/home/delia/Conversational_Robot/Conversational_Bot/src/utils/__init__.py
/home/delia/Conversational_Robot/Conversational_Bot/src/utils/debug_speech.py
/home/delia/Conversational_Robot/Conversational_Bot/src/utils/textnorm.py
/home/delia/Conversational_Robot/Conversational_Bot/src/wake/porcupine_engine.py
/home/delia/Conversational_Robot/Conversational_Bot/tools/export_code.py
/home/delia/Conversational_Robot/Conversational_Bot/voices/en_US-amy-medium.onnx.json
/home/delia/Conversational_Robot/Conversational_Bot/voices/ro_RO-mihai-medium.onnx.json

# CONTENT:

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/README.md =====
     1  # ğŸ§  Conversational Bot
     2  
     3  Private, local, lowâ€‘latency voice assistant with hotword detection, ASR, **streaming LLM â†’ streaming TTS**, bargeâ€‘in, and a tidy `/vitals` dashboard.
     4  
     5  ---
     6  
     7  ## âœ¨ Whatâ€™s implemented (and how)
     8  
     9  * **Wake word with safe fallback** â€” Porcupine hotword; if itâ€™s missing or fails, the app switches to **textâ€‘based wake matching** without crashing.
    10  * **ASR with clean endpointing** â€” Fasterâ€‘Whisper tuned for short turns; **standby** listens in tight windows; **active sessions** autoâ€‘detect RO/EN (standby favors EN for reliable hotwords).
    11  * **Streaming LLM â†’ streaming TTS** â€” Realâ€‘time token streaming to speech; **timeâ€‘toâ€‘firstâ€‘token (TTFT)** is measured so replies feel snappy.
    12  * **Audio hygiene** â€” System echoâ€‘cancel (AEC), noise suppression, highâ€‘pass filter; **AGC off** to avoid noise pumping & false VAD triggers.
    13  * **No accidental â€œpaâ€¦â€ exits** â€” Session closes **only** on exact goodbyes (e.g., â€œok byeâ€, â€œgataâ€, â€œla revedereâ€).
    14  * **Observability** â€” Prometheus counters + a simple `/vitals` page for roundâ€‘trip, ASR, TTFT, sessions, turns, errors.
    15  * **Double buffer for seamless TTS** â€” Prevents microâ€‘pauses when the bot speaks; while buffer A plays, buffer B synthesizes the next chunk, then they alternate continuously.
    16  * **English <> Romanian** â€” Improved command & QA flow in English while keeping full Romanian support.
    17  * **Honest fallback** â€” If the bot doesnâ€™t know, it says so (â€œIâ€™m not sure about that yet, but I can look it up if youâ€™d like.â€).
    18  
    19  ---
    20  
    21  ## ğŸ”§ Practical setup for users (do this)
    22  
    23  1. **Select the echoâ€‘cancelled mic**
    24     Use the `ec_mic` input (see Linux commands below). This is critical so the bot doesnâ€™t hear its own TTS as user speech.
    25  
    26  2. **Tune thresholds for your room**
    27  
    28  * `min_speech_duration`: **1.0â€“1.2s** (utterances shorter than this are ignored)
    29  * `silence_to_end`: **1200â€“1500 ms** (only for *active* session end, not standby)
    30  * Keep **AGC off** in the OS/driver and inside AEC if exposed.
    31  
    32  3. **Keys & env**
    33  
    34  * Put API keys in `.env`.
    35  * **Note:** Activating a venv does **not** read `.env` automatically. Either:
    36  
    37    * use `python-dotenv` inside the app, or
    38    * `export $(grep -v '^#' .env | xargs)` in your shell before `python -m src.app`.
    39  
    40  4. **Run with structured logs**
    41  
    42  ```bash
    43  LOG_LEVEL=INFO LOG_DIR=logs python -m src.app
    44  ```
    45  
    46  5. **(Optional) Hotword**
    47     Have a **Picovoice (Porcupine) key** for instant wake (â€œhello robotâ€). Without it, the fallback text matcher still works, just a bit less robust/lowâ€‘latency.
    48  
    49  ---
    50  
    51  ## ğŸ§© Mini flow (pipeline)
    52  
    53  **Standby & Wake** â†’ (Porcupine **or** text fallback)
    54  â†’ **Acknowledgement** (â€œYes, Iâ€™m listening.â€ / â€œDa, te ascult.â€)
    55  â†’ **Record & endpoint** (VAD on silence; AEC + NS + HPF; AGC off)
    56  â†’ **ASR** (Fasterâ€‘Whisper; session auto RO/EN; standby favors EN)
    57  â†’ **LLM** (streamed generation; **strictâ€‘facts** mode to reduce hallucinations)
    58  â†’ **TTS** (streamed **sentence chunks**)
    59  â†’ **Double buffer** (A plays while B synthesizes; swap)
    60  â†’ **Bargeâ€‘in** (if the user speaks, TTS stops; return to listening)
    61  â†’ **Session end** (idle timeout **or** exactâ€‘match goodbye)
    62  
    63  ---
    64  
    65  ## ğŸ™ï¸ Audio Architecture (AEC explained)
    66  
    67  **Goal:** prevent the botâ€™s own TTS from being misâ€‘detected as user speech.
    68  
    69  **How:** WebRTC AEC uses an **adaptive filter** that estimates the **echo path** (the transformation from farâ€‘end signal â†’ what the mic would hear). With the **farâ€‘end** signal (what we send to speakers) and the **nearâ€‘end** mic input, it continuously **predicts and subtracts** the echo component from the mic stream. This is *not* a static â€œroom fingerprintâ€; it adapts in real time as the environment changes.
    70  
    71  Extra guards we use:
    72  
    73  * **Exactâ€‘match goodbye only** (no partial â€œpaâ€¦â€ exits).
    74  * **Audio similarity veto**: if incoming mic frames highly correlate with the last TTS frames, ignore them.
    75  * **Voiceâ€‘only gating**: prioritize voiced segments for bargeâ€‘in (reduces knocks/claps).
    76  
    77  ---
    78  
    79  ## ğŸ§ª Biggest build obstacles (and fixes)
    80  
    81  * **Echo loop (bot hears itself)** â†’ solved with **systemâ€‘level AEC** and selecting `ec_mic`, AGC off, plus TTSâ€‘similarity veto.
    82  * **False exits on â€œpaâ€¦â€** â†’ fixed via **exactâ€‘match goodbyes** only.
    83  * **TTS microâ€‘pauses** â†’ fixed with **double buffering** (A plays while B synthesizes next chunk).
    84  * **Noiseâ€‘triggered bargeâ€‘in** â†’ improved by requiring **voiced segments** and raising the minimum speech duration.
    85  
    86  > **BIGGEST OBSTACLE â€” reliable bargeâ€‘in**: now solid with **Cobra VAD**. It also works *without* Picovoice (using WebRTC VAD + thresholds), but Cobra is more robust.
    87  
    88  ---
    89  
    90  ## ğŸ§° Linux audio: create echoâ€‘cancel devices (PulseAudio / PipeWire)
    91  
    92  > Many modern distros run **PipeWire** with a PulseAudio compatibility layer. The commands below work in both setups if the PulseAudio modules are available.
    93  
    94  ```bash
    95  # 1) Show current default sink/source
    96  pactl info | sed -n -e 's/^Default Sink: /Default Sink: /p' -e 's/^Default Source: /Default Source: /p'
    97  
    98  # 2) Unload any old echo-cancel (ignore errors if not loaded)
    99  pactl unload-module module-echo-cancel 2>/dev/null || true
   100  
   101  # 3) Load WebRTC echo-cancel on defaults
   102  DEFAULT_SINK="$(pactl info | awk -F': ' '/Default Sink/{print $2}')"
   103  DEFAULT_SOURCE="$(pactl info | awk -F': ' '/Default Source/{print $2}')"
   104  
   105  pactl load-module module-echo-cancel \
   106    aec_method=webrtc \
   107    aec_args="analog_gain_control=0 digital_gain_control=0" \
   108    use_master_format=1 \
   109    sink_master="$DEFAULT_SINK" \
   110    source_master="$DEFAULT_SOURCE" \
   111    sink_name=ec_speaker \
   112    source_name=ec_mic
   113  
   114  # 4) Make the echo-cancelled mic default
   115  pactl set-default-source ec_mic
   116  
   117  # 5) Verify
   118  pactl list short sources | grep -Ei 'ec_mic|echo|cancel'
   119  ```
   120  
   121  ## ğŸ”„ Models & reasoning
   122  
   123  * **ASR**: Started with OpenAI Whisper, switched to **Fasterâ€‘Whisper** for lower latency on CPU.
   124  * **LLM**: Started on **Llama** (strong bilingual allâ€‘rounder), then tested **Qwenâ€‘2.5 3B Instruct**. Keep a small, fast model for latency; pick based on your device.
   125  * **TTS**: Prefer **Piper** (fast, local). Fallback to `pyttsx3` if needed.
   126  * **Containerization**: Packaging everything in a container can give a **big reliability boost** (consistent deps, easy startup scripts), but is optional.
   127  * **â€œTeaser while thinkingâ€**: Considered a twoâ€‘brain approach (quick TL;DR line while the full answer loads). Dropped due to complexity vs. small latency benefit (most hard questions fit in ~3s extra).
   128  
   129  ---
   130  
   131  ## ğŸ—œï¸ Bargeâ€‘in reliability (with and without Picovoice)
   132  
   133  * **Works without Picovoice**: WebRTC VAD + tuned thresholds can pause TTS when a *human voice* is detected.
   134  * **Better with Picovoice**: **Cobra VAD** is more robust to noise; **Porcupine** gives instant â€œhello robotâ€ wake.
   135  * If you donâ€™t have keys, the app falls back to text matching for wake and to WebRTC VAD for bargeâ€‘in.
   136  
   137  **Proâ€‘tips**
   138  
   139  * Raise `min_speech_duration` to avoid coughs/knocks.
   140  * Use voicedâ€‘only gating for bargeâ€‘in.
   141  * Always select the **`ec_mic`** input.
   142  
   143  ---
   144  
   145  ## ğŸ§  LLM prompt (edit to your goals)
   146  
   147  Update `configs/llm.yaml` to reflect your assistantâ€™s role. Example fields worth tuning:
   148  
   149  * **system**: persona, safety rails, bilingual tone
   150  * **tools**: what the model may call
   151  * **style**: concise vs. exploratory
   152  * **facts mode**: stricter for correctness
   153  
   154  ---
   155  
   156  ## ğŸ› ï¸ Commands recap
   157  
   158  * **Run app with logs**
   159  
   160  ```bash
   161  LOG_LEVEL=INFO LOG_DIR=logs python -m src.app
   162  
   163  ```
   164  
   165  * **Load simple AEC setup** (see full commands above)
   166  * **Set default mic to `ec_mic`**
   167  * **Verify**: `pactl list short sources | grep -Ei 'ec_mic|echo|cancel'`
   168  
   169  ---
   170  
   171  ## ğŸ”œ Toâ€‘do (next iterations)
   172  
   173  * **Instant feedback while thinking** â€” quick filler like â€œThanks â€” give me a secâ€¦â€ if the first token is slow, then continue streaming the real answer.
   174  * **Model bakeâ€‘off** â€” compare **Phiâ€‘3 Mini (3.8B)** vs **Qwenâ€‘2.5 (3B)** vs current **Llama**; choose based on latency, fluency, and bilingual accuracy.
   175  
   176  ---
   177  
   178  ## ğŸ“¸ Vitals & diagram placeholders
   179  
   180  ![TTS AEC Schema](src/utils/tts_schema.png)
   181  
   182  ![Robot Vitals](src/utils/vitals.png)

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/configs/asr.yaml =====
     1  provider: faster            # faster | openai
     2  model_size: base            # tiny/base/small/medium/large-v2
     3  compute_type: int8          # int8 (CPU) | float16 (GPU) | int8_float16 (GPU slab)
     4  device: cpu                 # cpu | cuda
     5  beam_size: 1
     6  force_language:             # ex: en/ro, sau gol pentru auto
     7  vad_min_silence_ms: 300     # VAD intern (faster-whisper) â€“ endpointing mai â€snappyâ€

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/configs/audio.yaml =====
     1  sample_rate: 16000
     2  block_ms: 20
     3  
     4  # VAD agresiv pentru sesiuni (3 = cel mai strict)
     5  vad_aggressiveness: 3
     6  silence_ms_to_end: 1400
     7  max_record_seconds: 6
     8  session_idle_seconds: 12
     9  min_valid_seconds: 1.1
    10  
    11  # â€”â€”â€” BARGE-IN INTELIGENT (doar voce umanÄƒ) â€”â€”â€”
    12  barge_enabled: true
    13  barge_allow_during_tts: true
    14  barge_voice_hold_ms: 300          # pÄƒstreazÄƒ "vocea activÄƒ" cÃ¢teva sute ms pentru continuitate
    15  barge_debug_meter: false           # afiÈ™eazÄƒ Ã®n log un VU bar Ã®n timp ce ascultÄƒ (debug)
    16  barge_debug_interval_ms: 120       # cÃ¢t de des actualizeazÄƒ bara (ms)
    17  barge_voice_drop_ms: 10            # scade bufferul de voce cu 20ms la un bloc fÄƒrÄƒ vorbire
    18  
    19  # Prag temporal: cÃ¢t de multÄƒ voce continuÄƒ trebuie (filtru anti-impuls)
    20  barge_min_voice_ms: 250             # minim 350ms de voce continuÄƒ
    21  
    22  # Anti-eco TTS: nivelul minim acceptat (vocea e mai tare decÃ¢t TTS leak)
    23  barge_min_rms_dbfs: -31              # prag RMS ridicat: doar vorbire puternicÄƒ
    24  
    25  # Spectral filtering: ignorÄƒ frecvenÈ›e joase (bÄƒtÄƒi Ã®n masÄƒ ~50-200 Hz)
    26  barge_highpass_hz: 300               # taie tot sub 300 Hz (vocea start la ~80-100 Hz, dar energia e la 300+)
    27  
    28  # Zero-crossing rate: vocea umanÄƒ are ZCR moderat, zgomotele impulsive au ZCR extreme
    29  barge_zcr_min: 0.05                  # prag minim ZCR (anti-zgomot constant josfrekvent)
    30  barge_zcr_max: 0.35                  # prag maxim ZCR (anti-zgomot impulsiv Ã®nalt)
    31  
    32  # Debounce & cooldown (anti-trigger repetat)
    33  barge_debounce_ms: 150
    34  barge_cooldown_ms: 800
    35  barge_arm_after_ms: 400              # delay dupÄƒ pornirea listener-ului (evitÄƒ scurgeri iniÈ›iale)
    36  
    37  # Cobra VAD (Picovoice) â€” opÈ›ional, pentru detecÈ›ie robustÄƒ de vorbire
    38  cobra:
    39    enabled: true
    40    threshold: 0.55                   # p(speech) minim pentru a considera blocul ca vorbire
    41    hold_ms: 260                      # timp cÃ¢t pÄƒstreazÄƒ state-ul "Ã®n vorbire" dupÄƒ un frame activ
    42    access_key: "${PICOVOICE_ACCESS_KEY}"
    43    # library_path: "/path/to/libpv_cobra.so"
    44    # model_path: "/path/to/cobra_params.pv"
    45  
    46  # â€”â€”â€” Audio device & AEC â€”â€”â€”
    47  prefer_echo_cancel: true
    48  input_device_hint: "ec_mic"          # foloseÈ™te ec_mic creat de PulseAudio/PipeWire
    49  
    50  # AEC mode: system (preferat) | webrtc | off
    51  aec_mode: system                     # PulseAudio module-echo-cancel e deja activ
    52  monitor_device_hint: ""
    53  
    54  # Filtre simple din cod (AGC dezactivat pentru a pÄƒstra dinamica naturalÄƒ)
    55  ns: true
    56  agc: false
    57  hpf: true

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/configs/core.yaml =====
     1  fast_exit:
     2    enabled: true
     3    phrases: ["ok bye","ok, bye"]
     4    fuzzy: 90            
     5    debounce_ms: 120     # anti-spam
     6    min_chars: 2
     7    confirm_tts: "See you later !"   # gol "" dacÄƒ nu vrei feedback
     8    use_barge_check: true

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/configs/llm.yaml =====
     1  provider: ollama
     2  host: "http://127.0.0.1:11434"
     3  model: "llama3.2"
     4  max_tokens: 120
     5  temperature: 0.4
     6  language_policy: auto
     7  default_mode: precise         
     8  strict_facts: true  #daca nu stie spune ca nu stie 
     9  
    10  system_prompt: |-
    11    You are a local voice assistant for a humanoid robot; reply in the userâ€™s language (ro/en) with 1â€“3 short sentences

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/configs/routing.yaml =====
     1  rules: []
===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/configs/tts.yaml =====
     1  backend: piper
     2  rate: 180
     3  volume: 0.7
     4  voice_ro_hint: "ro"
     5  voice_en_hint: "en"
     6  
     7  piper:
     8    exe: "/home/delia/Conversational_Robot/Conversational_Bot/.venv/bin/piper"     # verificÄƒ cu: which piper
     9    model_ro: "voices/ro_RO-mihai-medium.onnx"
    10    config_ro: "voices/ro_RO-mihai-medium.onnx.json"
    11    model_en: "voices/en_US-amy-medium.onnx" 
    12    config_en: "voices/en_US-amy-medium.onnx.json"
    13    speaker_id: null
    14    length_scale: 1.0
    15    noise_scale: 0.667
    16    noise_w: 0.8
    17    sentence_silence_ms: 80

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/configs/wake.yaml =====
     1  engine: porcupine    # porcupine | asr
     2  threshold: 60
     3  wake_phrases:
     4    - "hello robot"
     5    - "hey robot"
     6    - "salut robot"
     7    - "hei robot"
     8    - "buna robot"
     9  
    10  acknowledgement:
    11    ro: "Da, te ascult."
    12    en: "Yes, I'm listening."
    13  
    14  porcupine:
    15    # Obligatoriu: cheie Picovoice (set-o aici sau prin env PICOVOICE_ACCESS_KEY)
    16    access_key: "${PICOVOICE_ACCESS_KEY}"
    17  
    18    # Variante:
    19    # 1) custom keyword(s) .ppn â€” recomandat pt 'hello robot'
    20    keyword_paths:
    21      - "/home/dani/Hello-Robot_en_linux_v3_0_0/Hello-Robot_en_linux_v3_0_0.ppn"
    22    keywords:
    23      - "porcupine"
    24    
    25    sensitivities: [0.6]

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_100811/00_asr.txt =====
     1  No!

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_100811/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_100811/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_104602/00_asr.txt =====
     1  Explain sleep.

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_104602/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_104602/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_110133/00_asr.txt =====
     1  Nici, vreau sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ vÄƒzÄƒm sÄƒ v

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_110133/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_110133/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_111001/00_asr.txt =====
     1  Explain sleep.

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_111001/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_111001/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_112548/00_asr.txt =====
     1  What is sleep?

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_112548/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_112548/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_114256/00_asr.txt =====
     1  Explain sleep.

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_114256/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_114256/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124004/00_asr.txt =====
     1  Sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, sunt, s

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124004/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124004/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124030/00_asr.txt =====
     1  Explain sleep.

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124030/10_llm_stream.txt =====
     1  Sleep is a natural process that occurs when our body needs to rest and recharge. During sleep, our brain processes memories
===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124030/20_spoken_text.txt =====
     1  Sleep is a natural process that occurs when our body needs to rest and recharge. During sleep, our brain processes memories
===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124210/00_asr.txt =====
     1  Explain characters

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124210/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124210/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124352/00_asr.txt =====
     1  Explain sleep.

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124352/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124352/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124425/00_asr.txt =====
     1  Explain sleep.

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124425/10_llm_stream.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/data/debug/20251106_124425/20_spoken_text.txt =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/requirements.txt =====
     1  setuptools<81
     2  # Core audio I/O
     3  sounddevice==0.4.6
     4  soundfile==0.12.1
     5  webrtcvad==2.0.10
     6  PyYAML==6.0.2
     7  numpy==1.26.4
     8  
     9  # Speech-to-text (ASR)
    10  faster-whisper==1.0.3
    11  #openai-whisper==20231117
    12  
    13  # Text-to-speech (TTS)
    14  pyttsx3==2.91
    15  
    16  # LLM / HTTP
    17  requests==2.32.3
    18  
    19  # Logging / dev utilities
    20  coloredlogs==15.0.1
    21  
    22  # (Optional) quality-of-life tools
    23  tqdm==4.66.5
    24  rapidfuzz==3.9.6
    25  
    26  #Observability
    27  prometheus_client==0.20.0
    28  pydantic==2.8.2
    29  python-json-logger==2.0.7
    30  rich==13.7.1
    31  
    32  #wake word
    33  pvporcupine==3.0.2
    34  python-dotenv==1.0.1
===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/__init__.py =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/app.py =====
     1  # src/app.py
     2  from pathlib import Path
     3  import os
     4  import time
     5  from rapidfuzz import fuzz
     6  from dotenv import load_dotenv, find_dotenv
     7  
     8  from src.core.fast_exit import FastExit
     9  from src.core.states import BotState
    10  from src.core.logger import setup_logger
    11  from src.core.config import load_all
    12  from src.audio.input import record_until_silence
    13  from src.audio.barge import BargeInListener
    14  from src.asr import make_asr
    15  from src.llm.engine import LLMLocal
    16  from src.tts.engine import TTSLocal
    17  from src.core.wake import WakeDetector
    18  from src.utils.textnorm import normalize_text
    19  from src.audio.wake_porcupine import wait_for_wake as wait_for_wake_porcupine
    20  from src.llm.stream_shaper import shape_stream  # netezire stream LLMâ†’TTS
    21  
    22  from src.telemetry.metrics import (
    23      boot_metrics, round_trip, wake_triggers, sessions_started,
    24      sessions_ended, interactions, unknown_answer, errors_total,
    25      tts_speak_calls
    26  )
    27  
    28  LANG_MAP = {"ro": "ro", "en": "en"}
    29  
    30  # 1) Ã®ncarcÄƒ .env din CWD (nu suprascrie ENV deja setate)
    31  load_dotenv(find_dotenv(".env", usecwd=True), override=False)
    32  
    33  # 2) root = Conversational_Bot
    34  ROOT = Path(__file__).resolve().parents[1]
    35  
    36  # 3) Ã®ncearcÄƒ È™i repo/.env + configs/.env
    37  load_dotenv(ROOT / ".env", override=False)
    38  load_dotenv(ROOT / "configs" / ".env", override=False)
    39  
    40  
    41  def _lang_from_code(code: str) -> str:
    42      code = (code or "en").lower()
    43      for k in LANG_MAP:
    44          if code.startswith(k):
    45              return LANG_MAP[k]
    46      return "en"
    47  
    48  
    49  def is_goodbye(text: str) -> bool:
    50      t = normalize_text(text)
    51      if not t:
    52          return False
    53      # doar potriviri exacte; evitÄƒm trigger la cuvinte mai lungi (ex: "paine")
    54      bye_exact = {
    55          "ok bye", "okay bye", "bye", "goodbye",
    56          "stop", "cancel", "enough",
    57          "gata", "la revedere", "opreste", "oprim", "terminam"
    58      }
    59      return t in bye_exact
    60  
    61  
    62  def main():
    63      logger = setup_logger()
    64      addr, port = boot_metrics()
    65      logger.info(f"ğŸ“ˆ Metrics UI: http://{addr}:{port}/vitals  |  Prometheus: http://{addr}:{port}/metrics")
    66  
    67      cfg = load_all()
    68      data_dir = Path(cfg["paths"]["data"])
    69      data_dir.mkdir(parents=True, exist_ok=True)
    70  
    71      # Engines
    72      asr = make_asr(cfg["asr"], logger)
    73      llm = LLMLocal(cfg["llm"], logger)
    74      tts = TTSLocal(cfg["tts"], logger)
    75  
    76      # Wake options
    77      wake = WakeDetector(cfg["wake"], logger)
    78      ack_ro = cfg["wake"]["acknowledgement"]["ro"]
    79      ack_en = cfg["wake"]["acknowledgement"]["en"]
    80  
    81      # -------- Porcupine config + fallback sigur --------
    82      WAKE_ENGINE = (os.getenv("WAKE_ENGINE") or cfg["wake"].get("engine") or "auto").lower()
    83  
    84      PV_KEY = (
    85          os.getenv("PICOVOICE_ACCESS_KEY", "").strip()
    86          or (cfg["wake"].get("porcupine", {}) or {}).get("access_key", "").strip()
    87      )
    88      PPN_PATH = (
    89          os.getenv("PORCUPINE_PPN", "").strip()
    90          or next(iter((cfg["wake"].get("porcupine", {}) or {}).get("keyword_paths", []) or []), "")
    91      )
    92      PORC_SENS = float(os.getenv("PORCUPINE_SENSITIVITY", "0.6"))
    93      PORC_LANG = (os.getenv("PORCUPINE_LANG", "en") or "en").lower()
    94  
    95      missing = []
    96      if not PV_KEY:
    97          missing.append("PICOVOICE_ACCESS_KEY")
    98      if not PPN_PATH:
    99          missing.append("PORCUPINE_PPN")
   100      elif not Path(PPN_PATH).exists():
   101          missing.append(f"ppn missing: {PPN_PATH}")
   102  
   103      # PoliticÄƒ de selectare:
   104      # - 'porcupine' -> doar dacÄƒ cheile/fiÈ™ierul sunt valide; altfel fallback la text + warning
   105      # - 'auto' -> porcupine dacÄƒ e configurat complet; altfel text
   106      use_porcupine = False
   107      if WAKE_ENGINE == "porcupine":
   108          if not missing:
   109              use_porcupine = True
   110          else:
   111              logger.warning(f"ğŸ”• Porcupine cerut, dar lipsesc: {', '.join(missing)} â€” fac fallback pe wake via text (ASR).")
   112              use_porcupine = False
   113      elif WAKE_ENGINE == "auto":
   114          use_porcupine = (len(missing) == 0)
   115      else:
   116          use_porcupine = False
   117  
   118      logger.info(f"ğŸ”” Wake engine: {'porcupine' if use_porcupine else 'text'}")
   119      if not use_porcupine:
   120          logger.info("â„¹ï¸ Hint: seteazÄƒ PICOVOICE_ACCESS_KEY È™i PORCUPINE_PPN Ã®n configs/.env sau engine=asr.")
   121  
   122      # â€circuit breakerâ€: dacÄƒ Porcupine eÈ™ueazÄƒ repetat la runtime -> trecem pe text pÃ¢nÄƒ la repornire
   123      porcupine_failures = 0
   124      PORCUPINE_MAX_FAILS = 3
   125  
   126      logger.info("ğŸ¤– Standby: spune â€hello robotâ€ sau â€salut robotâ€ ca sÄƒ porneÈ™ti conversaÈ›ia.")
   127      state = BotState.LISTENING
   128      fast_exit_cfg = (cfg.get("fast_exit") or cfg.get("core", {}).get("fast_exit") or {})
   129      fast_exit = FastExit(tts, llm, state, logger, fast_exit_cfg, barge=None)
   130  
   131      # ÃncercÄƒm sÄƒ ne conectÄƒm la "partial" / "final" dacÄƒ ASR expune callback-uri.
   132      try:
   133          # VARIANTA A: atribut direct on_partial
   134          old_partial_cb = getattr(asr, "on_partial", None)
   135          if callable(old_partial_cb) or hasattr(asr, "on_partial"):
   136              def _combined_partial_cb(text, *a, **kw):
   137                  if fast_exit.on_partial(text):
   138                      return  # consumÄƒ evenimentul -> opreÈ™te streamul
   139                  if callable(old_partial_cb):
   140                      return old_partial_cb(text, *a, **kw)
   141              asr.on_partial = _combined_partial_cb
   142          # VARIANTA B: registru de callback-uri
   143          elif hasattr(asr, "register_callback"):
   144              try:
   145                  asr.register_callback("partial", lambda text, *a, **kw: fast_exit.on_partial(text))
   146              except Exception:
   147                  pass
   148          elif hasattr(asr, "add_listener"):
   149              try:
   150                  asr.add_listener("partial", lambda text, *a, **kw: fast_exit.on_partial(text))
   151              except Exception:
   152                  pass
   153  
   154          # Fallback È™i pe transcriptul final
   155          if hasattr(asr, "on_final"):
   156              old_final_cb = getattr(asr, "on_final", None)
   157              def _combined_final_cb(text, *a, **kw):
   158                  if fast_exit.on_final(text):
   159                      return
   160                  if callable(old_final_cb):
   161                      return old_final_cb(text, *a, **kw)
   162              asr.on_final = _combined_final_cb
   163      except Exception:
   164          logger.debug("FastExit: ASR nu expune hook-uri de partial/final â€” continui fÄƒrÄƒ.")
   165  
   166      last_bot_reply = ""  # anti-eco
   167  
   168      try:
   169          while True:
   170              # â€”â€” STANDBY: Porcupine (dacÄƒ e activ È™i nu s-a â€arsâ€ breaker-ul) â€”â€”
   171              if use_porcupine:
   172                  ok = wait_for_wake_porcupine(
   173                      cfg_audio=cfg["audio"],
   174                      access_key=PV_KEY,
   175                      keyword_path=PPN_PATH,
   176                      sensitivity=PORC_SENS,
   177                      logger=logger,
   178                      timeout_seconds=None
   179                  )
   180                  if not ok:
   181                      porcupine_failures += 1
   182                      if porcupine_failures >= PORCUPINE_MAX_FAILS:
   183                          logger.warning("âš ï¸ Porcupine a eÈ™uat repetat â€” comut pe wake via text pentru sesiunea curentÄƒ.")
   184                          use_porcupine = False
   185                      time.sleep(0.1)
   186                      continue
   187                  porcupine_failures = 0
   188                  matched = "wake-porcupine"
   189                  heard_lang = "ro" if PORC_LANG.startswith("ro") else "en"
   190                  logger.info("ğŸ”” Wake phrase detectatÄƒ (porcupine)")
   191                  wake_triggers.inc()
   192              else:
   193                  # â€”â€” STANDBY: text-ASR + fuzzy match â€”â€”
   194                  standby_cfg = dict(cfg["audio"])
   195                  standby_cfg.update({
   196                      "silence_ms_to_end": 1000,
   197                      "max_record_seconds": 4,
   198                      "vad_aggressiveness": 3,
   199                      "min_valid_seconds": 0.7,
   200                  })
   201                  standby_wav = data_dir / "cache" / "standby.wav"
   202                  standby_wav.parent.mkdir(parents=True, exist_ok=True)
   203                  path, dur = record_until_silence(standby_cfg, standby_wav, logger)
   204  
   205                  if dur < float(standby_cfg.get("min_valid_seconds", 0.7)):
   206                      logger.info(f"â­ï¸ standby prea scurt (dur={dur:.2f}s) â€” reiau")
   207                      continue
   208  
   209                  # forÈ›Äƒm EN Ã®n standby
   210                  result = asr.transcribe(path, language_override="en")
   211                  heard_text = (result.get("text") or "").strip()
   212                  heard_lang = "en"
   213  
   214                  scores = wake.debug_scores(heard_text)
   215                  logger.info(f"ğŸ‘‚ [standby:{heard_lang}] {heard_text} | wake-scores: {scores}")
   216  
   217                  if not heard_text:
   218                      continue
   219  
   220                  matched = wake.match(heard_text)
   221                  if not matched:
   222                      continue
   223  
   224                  logger.info(f"ğŸ”” Wake phrase detectatÄƒ: {matched}")
   225                  wake_triggers.inc()
   226                  matched_norm = normalize_text(matched)
   227                  ro_phrases = [normalize_text(p) for p in cfg["wake"]["wake_phrases"]
   228                                if "robot" in p and any(x in p.lower() for x in ["salut", "hei", "bun"])]
   229                  heard_lang = "ro" if any(matched_norm == rp for rp in ro_phrases) else "en"
   230  
   231              # â€”â€” Wake confirm â€”â€”
   232              ack = ack_ro if heard_lang == "ro" else ack_en
   233              tts_speak_calls.inc()
   234              tts.say(ack, lang=heard_lang)
   235  
   236              # â€”â€” SESIUNE MULTI-TURN â€”â€”
   237              ask_cfg = dict(cfg["audio"])
   238              ask_cfg.update({
   239                  # scurteazÄƒ endpointing-ul Ã®n sesiune (nu afecteazÄƒ standby)
   240                  "silence_ms_to_end": 450,        # de la 1400 -> ~450ms
   241                  "max_record_seconds": int(cfg["audio"].get("max_record_seconds", 6)),
   242                  "vad_aggressiveness": int(cfg["audio"].get("vad_aggressiveness", 3)),
   243  
   244                  # important: permite utterance scurt pentru "ok bye"
   245                  "min_valid_seconds": 0.35,       # permiÈ›i fraze foarte scurte
   246              })
   247  
   248              logger.info("ğŸŸ¢ Sesiune activÄƒ (spune â€ok byeâ€ ca sÄƒ Ã®nchizi).")
   249              state = BotState.LISTENING
   250              sessions_started.inc()
   251  
   252              fast_exit.reset()
   253  
   254              # iniÈ›ializÄƒri lipsÄƒ (FIX)
   255              session_idle_seconds = int(cfg["audio"].get("session_idle_seconds", 12))
   256              last_activity = time.time()
   257  
   258              while time.time() - last_activity < session_idle_seconds:
   259                  user_wav = data_dir / "cache" / "user_utt.wav"
   260                  path_user, dur = record_until_silence(ask_cfg, user_wav, logger)
   261  
   262                  if dur < float(ask_cfg.get("min_valid_seconds", 0.35)):
   263                      continue
   264  
   265                  state = BotState.THINKING
   266  
   267                  # â€”â€”â€” ASR: strict RO/EN â€”â€”â€”
   268                  asr_res = None
   269                  user_text = ""
   270                  user_lang = "en"
   271                  try:
   272                      if hasattr(asr, "transcribe_ro_en"):
   273                          asr_res = asr.transcribe_ro_en(path_user)
   274                      else:
   275                          asr_res = asr.transcribe(path_user, language_override="en")
   276                      user_text = (asr_res.get("text") or "").strip()
   277                      user_lang = asr_res.get("lang", "en")
   278                      if user_lang not in ("ro", "en"):
   279                          user_lang = "en"
   280                  except Exception:
   281                      asr_res = {"text": "", "lang": "en"}
   282                      user_text = ""
   283                      user_lang = "en"
   284  
   285                  logger.info(f"ğŸ§ [{user_lang}] {user_text}")
   286  
   287                  # â€”â€”â€” Anti-eco textual â€”â€”â€”
   288                  try:
   289                      ut = normalize_text(user_text)
   290                      bt = normalize_text(last_bot_reply)
   291                      if len(ut) > 8 and len(bt) > 8:
   292                          sim = fuzz.partial_ratio(ut, bt)
   293                          if sim >= 85:
   294                              logger.info(f"ğŸ”‡ Ignor input (eco TTS) sim={sim}")
   295                              continue
   296                  except Exception:
   297                      pass
   298  
   299                  if not user_text:
   300                      continue
   301  
   302                  # FastExit (inclusiv pe transcript final)
   303                  if fast_exit.on_final(user_text):
   304                      logger.info("ğŸ”´ FastExit: Ã®nchis pe transcript final.")
   305                      break
   306  
   307                  # Ã®nchidere sesiune pe "ok bye"
   308                  if is_goodbye(user_text):
   309                      state = BotState.SPEAKING
   310                      tts_speak_calls.inc()
   311                      tts.say("Bine, pa!" if user_lang == "ro" else "Okay, bye!", lang=user_lang)
   312                      logger.info("ğŸ”´ Sesiune Ã®nchisÄƒ de utilizator (ok bye).")
   313                      break
   314  
   315                  # â€”â€”â€” STREAMING: LLM â†’ TTS â€”â€”â€”
   316                  interactions.inc()
   317                  rt_start = time.perf_counter()
   318  
   319                  # === Debug dir per sesiune ===
   320                  from datetime import datetime
   321                  from src.utils.debug_speech import DebugSpeech
   322                  session_dir = data_dir / "debug" / datetime.now().strftime("%Y%m%d_%H%M%S")
   323                  debugger = DebugSpeech(session_dir, user_lang, logger)
   324                  debugger.write_asr(user_text)
   325  
   326                  reply_buf = []
   327  
   328                  def _capture(gen):
   329                      # tee generatorul cu debugger.tee
   330                      for tok in debugger.tee(gen):
   331                          reply_buf.append(tok)
   332                          yield tok
   333  
   334                  token_iter_raw = llm.generate_stream(user_text, lang_hint=user_lang, mode="precise")
   335  
   336                  # netezeÈ™te streamul Ã®n fraze stabile:
   337                  shaped = shape_stream(
   338                      token_iter_raw,
   339                      prebuffer_chars=120,
   340                      min_chunk_chars=int(cfg["tts"].get("min_chunk_chars", 60)),
   341                      soft_max_chars=140,
   342                      max_idle_ms=250,
   343                  )
   344  
   345                  # Capture + gard de oprire
   346                  def _abort_guard(gen):
   347                      for tok in gen:
   348                          if fast_exit.pending():
   349                              break
   350                          yield tok
   351  
   352                  token_iter = _capture(_abort_guard(shaped))
   353  
   354                  def _mark_tts_start():
   355                      # round-trip metric
   356                      round_trip.observe(time.perf_counter() - rt_start)
   357                      # debug hook
   358                      debugger.on_tts_start()
   359  
   360                  state = BotState.SPEAKING
   361                  tts_speak_calls.inc()
   362                  tts.say_async_stream(
   363                      token_iter,
   364                      lang=user_lang,
   365                      on_first_speak=_mark_tts_start,
   366                      min_chunk_chars=int(cfg["tts"].get("min_chunk_chars", 60)),
   367                  )
   368  
   369                  # BARGE-IN Ã®n timpul TTS (protejatÄƒ anti-eco È™i cu arm-delay)
   370                  if not bool(cfg["audio"].get("barge_enabled", True)):
   371                      while tts.is_speaking():
   372                          if fast_exit.pending():
   373                              tts.stop()
   374                              break
   375                          time.sleep(0.05)
   376                  elif not bool(cfg["audio"].get("barge_allow_during_tts", True)):
   377                      while tts.is_speaking():
   378                          if fast_exit.pending():
   379                              tts.stop()
   380                              break
   381                          time.sleep(0.05)
   382                  else:
   383                      barge = BargeInListener(cfg["audio"], logger)
   384                      fast_exit.barge = barge  # permite FastExit sÄƒ verifice cÄƒ vorbeÈ™te userul, nu eco TTS
   385                      try:
   386                          while tts.is_speaking():
   387                              if fast_exit.pending():
   388                                  tts.stop()
   389                                  break
   390                              need = int(cfg["audio"].get("barge_min_voice_ms", 650))
   391                              if barge.heard_speech(need_ms=need):
   392                                  logger.info("â›” Barge-in detectat â€” opresc TTS È™i trec la listening.")
   393                                  tts.stop()
   394                                  break
   395                              time.sleep(0.03)
   396                      finally:
   397                          barge.close()
   398  
   399                  # finalizeazÄƒ logurile
   400                  debugger.on_tts_end()
   401                  last_bot_reply = "".join(reply_buf)
   402                  debugger.finish()
   403                  if fast_exit.pending():
   404                      logger.info("ğŸ”´ FastExit: sesiune Ã®nchisÄƒ (revenire Ã®n standby).")
   405                      break
   406  
   407                  last_activity = time.time()
   408  
   409              # â€”â€” ieÈ™ire din sesiune => standby â€”â€”
   410              state = BotState.LISTENING
   411              logger.info("â³ Revenire Ã®n standby (spune din nou wake-phrase pentru o nouÄƒ sesiune).")
   412              sessions_ended.inc()
   413  
   414      except KeyboardInterrupt:
   415          logger.info("Bye!")
   416      except Exception as e:
   417          errors_total.inc()
   418          logger.exception(f"Fatal error: {e}")
   419  
   420  
   421  if __name__ == "__main__":
   422      main()

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/asr/__init__.py =====
     1  # src/asr/__init__.py
     2  from typing import Optional
     3  from src.core.logger import setup_logger
     4  
     5  def make_asr(cfg_asr: dict, logger=None):
     6      if logger is None:
     7          logger = setup_logger("asr")
     8      provider = (cfg_asr.get("provider") or "faster").lower()
     9      if provider == "faster":
    10          from .engine_faster import ASREngine
    11          return ASREngine(
    12              model_size=cfg_asr.get("model_size", "base"),
    13              compute_type=cfg_asr.get("compute_type", "int8"),
    14              device=cfg_asr.get("device", "cpu"),
    15              force_language=cfg_asr.get("force_language"),
    16              beam_size=int(cfg_asr.get("beam_size", 1)),
    17              vad_min_silence_ms=int(cfg_asr.get("vad_min_silence_ms", 300)),
    18          )
    19      elif provider == "openai":
    20          from .engine_openai import ASREngine
    21          return ASREngine(
    22              model_size=cfg_asr.get("model_size", "base"),
    23              compute_type=cfg_asr.get("compute_type"),
    24              device=cfg_asr.get("device", "cpu"),
    25              force_language=cfg_asr.get("force_language"),
    26          )
    27      else:
    28          raise ValueError(f"Unknown ASR provider: {provider}")

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/asr/engine_faster.py =====
     1  # src/asr/engine_faster.py
     2  from __future__ import annotations
     3  from pathlib import Path
     4  from typing import Dict, Any, Optional, Tuple, List
     5  from faster_whisper import WhisperModel
     6  
     7  from src.telemetry.metrics import observe_hist, asr_latency
     8  
     9  class ASREngine:
    10      def __init__(
    11          self,
    12          model_size: str = "base",
    13          compute_type: str = "int8",     # int8 / int8_float16 / float16 / float32
    14          device: str = "cpu",            # cpu / cuda
    15          force_language: Optional[str] = None,
    16          beam_size: int = 1,
    17          vad_min_silence_ms: int = 300,
    18      ):
    19          self.force_language = (force_language or "").strip().lower() or None
    20          self.beam_size = int(beam_size or 1)
    21          self.vad_min_silence_ms = int(vad_min_silence_ms or 300)
    22          self.model = WhisperModel(
    23              model_size,
    24              device=device,
    25              compute_type=compute_type,
    26              download_root=None,
    27          )
    28          print(f"[ASR] faster-whisper model={model_size} device={device} compute_type={compute_type} "
    29                f"force_language={self.force_language} vad_min_silence_ms={self.vad_min_silence_ms}")
    30  
    31      # ---- helper intern
    32      def _run_once(self, wav_path: str | Path, language: Optional[str], use_vad: bool) -> Tuple[str, str, float, float]:
    33          """
    34          ReturneazÄƒ: (text, lang_out, lang_prob, score)
    35          score = medie(avg_logprob pe segmente) + 0.01 * len(text)
    36          """
    37          segments, info = self.model.transcribe(
    38              str(wav_path),
    39              language=language,
    40              beam_size=self.beam_size,
    41              temperature=0.0,
    42              vad_filter=use_vad,
    43              vad_parameters={"min_silence_duration_ms": self.vad_min_silence_ms} if use_vad else None,
    44              no_speech_threshold=0.6,
    45              log_prob_threshold=-0.5,
    46              condition_on_previous_text=False,
    47          )
    48          segs: List = list(segments)
    49          text = "".join(s.text for s in segs).strip()
    50          # scor simplu È™i robust
    51          if segs:
    52              # uneori s.avg_logprob lipseÈ™te; folosim -5.0 default
    53              vals = [getattr(s, "avg_logprob", -5.0) if getattr(s, "avg_logprob", None) is not None else -5.0 for s in segs]
    54              avg_lp = sum(vals) / len(vals)
    55          else:
    56              avg_lp = -9.0
    57          score = avg_lp + 0.01 * len(text)
    58          out_lang = info.language or (language or "en")
    59          prob = float(getattr(info, "language_probability", 0.0) or 0.0)
    60          return text, out_lang, prob, score
    61  
    62      # ---- API standard (pÄƒstrat, dar robust la bug-ul cu max() pe colecÈ›ie vidÄƒ)
    63      def transcribe(self, wav_path: str | Path, language_override: Optional[str] = None) -> Dict[str, Any]:
    64          lang = (language_override or self.force_language or None)
    65          with observe_hist(asr_latency):
    66              try:
    67                  text, out_lang, prob, _ = self._run_once(wav_path, lang, use_vad=True)
    68              except ValueError as e:
    69                  if "max() iterable argument is empty" in str(e):
    70                      fallback_lang = lang or "en"
    71                      text, out_lang, prob, _ = self._run_once(wav_path, fallback_lang, use_vad=False)
    72                  else:
    73                      raise
    74          return {"text": text, "lang": out_lang, "language_probability": prob}
    75  
    76      # ---- NOU: transcriere strict EN/RO -> alegem cea mai bunÄƒ
    77      def transcribe_ro_en(self, wav_path: str | Path) -> Dict[str, Any]:
    78          with observe_hist(asr_latency):
    79              # rulÄƒm EN & RO cu VAD intern; dacÄƒ dÄƒ eroare, retry fÄƒrÄƒ VAD
    80              def safe(lang):
    81                  try:
    82                      return self._run_once(wav_path, lang, use_vad=True)
    83                  except ValueError as e:
    84                      if "max() iterable argument is empty" in str(e):
    85                          return self._run_once(wav_path, lang, use_vad=False)
    86                      raise
    87              en_text, _, _, en_score = safe("en")
    88              ro_text, _, _, ro_score = safe("ro")
    89  
    90          if (ro_score > en_score) and ro_text:
    91              return {"text": ro_text, "lang": "ro", "language_probability": 1.0}
    92          else:
    93              return {"text": en_text, "lang": "en", "language_probability": 1.0}

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/asr/engine_openai.py =====
     1  # src/asr/engine_openai.py
     2  from __future__ import annotations
     3  from pathlib import Path
     4  from typing import Dict, Any, Optional
     5  import whisper
     6  
     7  # metrics
     8  from src.telemetry.metrics import observe_hist, asr_latency
     9  
    10  class ASREngine:
    11      def __init__(
    12          self,
    13          model_size: str = "tiny",
    14          compute_type: str | None = None,
    15          device: str = "cpu",
    16          force_language: Optional[str] = None,
    17      ):
    18          self.device = "cuda" if device == "cuda" else "cpu"
    19          self.fp16 = (self.device == "cuda")
    20          name = model_size if model_size in {"tiny","base","small","medium","large"} else "tiny"
    21          self.model = whisper.load_model(name, device=self.device)
    22          self.force_language = (force_language or "").strip().lower() or None
    23          print(f"[ASR] openai-whisper model={name} device={self.device} fp16={self.fp16} force_language={self.force_language}")
    24  
    25      def transcribe(self, wav_path: str | Path, language_override: Optional[str] = None) -> Dict[str, Any]:
    26          lang = (language_override or self.force_language or None)
    27          with observe_hist(asr_latency):
    28              res = self.model.transcribe(
    29                  str(wav_path),
    30                  fp16=self.fp16,
    31                  language=lang,
    32                  temperature=0.0,
    33                  condition_on_previous_text=False,
    34                  no_speech_threshold=0.6,
    35                  logprob_threshold=-0.5,
    36              )
    37          text = (res.get("text") or "").strip()
    38          out_lang = res.get("language") or (lang or "en")
    39          return {"text": text, "lang": out_lang, "language_probability": 0.0}

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/__init__.py =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/aec_webrtc.py =====
     1  # src/audio/aec_webrtc.py
     2  from __future__ import annotations
     3  import numpy as np
     4  
     5  class WebRTCAEC:
     6      """
     7      Stub AEC: Ã®ntoarce frame-ul nemodificat.
     8      Ãnlocuim cu implementare realÄƒ (WebRTC APM) cÃ¢nd dorim aec_mode=webrtc.
     9      """
    10      def __init__(self, sample_rate: int = 16000, frame_ms: int = 20):
    11          self.sr = sample_rate
    12          self.frame_ms = frame_ms
    13  
    14      def process_frame(self, pcm_i16: np.ndarray) -> np.ndarray:
    15          return pcm_i16
    16  
    17      def close(self):
    18          pass

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/barge.py =====
     1  # src/audio/barge.py - Barge-in inteligent (doar voce umanÄƒ)
     2  from __future__ import annotations
     3  import os
     4  import sounddevice as sd
     5  import numpy as np
     6  import queue, time, struct, math
     7  from typing import Optional
     8  from .vad import VAD
     9  from .devices import choose_input_device
    10  
    11  try:
    12      import pvcobra  # type: ignore
    13  except ImportError:  # pragma: no cover - optional dependency
    14      pvcobra = None
    15  
    16  def _rms_dbfs(pcm_i16: np.ndarray) -> float:
    17      """CalculeazÄƒ RMS Ã®n dBFS."""
    18      if pcm_i16.size == 0:
    19          return -120.0
    20      xf = pcm_i16.astype(np.float32) / 32768.0
    21      rms = float(np.sqrt(np.mean(xf * xf) + 1e-12))
    22      return 20.0 * np.log10(rms + 1e-12)
    23  
    24  def _highpass_filter(pcm_i16: np.ndarray, cutoff_hz: float, sr: int) -> np.ndarray:
    25      """
    26      Filtru high-pass simplu (first-order IIR) pentru a tÄƒia frecvenÈ›ele joase.
    27      EliminÄƒ zgomotele de tip bÄƒtÄƒi Ã®n masÄƒ (~50-200 Hz).
    28      """
    29      if cutoff_hz <= 0:
    30          return pcm_i16
    31      
    32      # Coeficient pentru filtrul IIR: alpha = RC / (RC + dt)
    33      rc = 1.0 / (2.0 * np.pi * cutoff_hz)
    34      dt = 1.0 / sr
    35      alpha = rc / (rc + dt)
    36      
    37      xf = pcm_i16.astype(np.float32)
    38      y = np.zeros_like(xf)
    39      y_prev = 0.0
    40      x_prev = 0.0
    41      
    42      for i in range(len(xf)):
    43          y[i] = alpha * (y_prev + xf[i] - x_prev)
    44          y_prev = y[i]
    45          x_prev = xf[i]
    46      
    47      return np.clip(y, -32768, 32767).astype(np.int16)
    48  
    49  def _zero_crossing_rate(pcm_i16: np.ndarray) -> float:
    50      """
    51      CalculeazÄƒ rata de treceri prin zero (ZCR).
    52      Vocea umanÄƒ: ZCR moderat (~0.05-0.3)
    53      Zgomote impulsive: ZCR foarte mare (>0.4)
    54      Zgomote joase constante: ZCR foarte mic (<0.02)
    55      """
    56      if len(pcm_i16) < 2:
    57          return 0.0
    58      signs = np.sign(pcm_i16)
    59      crossings = np.sum(np.abs(np.diff(signs))) / 2.0
    60      return crossings / (len(pcm_i16) - 1)
    61  
    62  
    63  class BargeInListener:
    64      """
    65      Listener inteligent pentru barge-in:
    66      - DetecteazÄƒ DOAR voce umanÄƒ (VAD + RMS + spectral filtering + ZCR)
    67      - IgnorÄƒ bÄƒtÄƒi Ã®n masÄƒ, ecoul TTS, zgomote impulsive
    68      - Anti-impuls: voce continuÄƒ >= barge_min_voice_ms
    69      """
    70      def __init__(self, cfg_audio: dict, logger):
    71          self.log = logger
    72          self.sr = int(cfg_audio["sample_rate"])
    73          self.block_ms = int(cfg_audio["block_ms"])
    74          self.block = int(self.sr * (self.block_ms / 1000.0))
    75  
    76          # â€”â€”â€” Cobra VAD (opÈ›ional) â€”â€”â€”
    77          cobra_cfg = cfg_audio.get("cobra") or {}
    78          cobra_enabled_cfg = cobra_cfg.get("enabled", cfg_audio.get("barge_use_cobra", False))
    79          self.cobra_threshold = float(cobra_cfg.get("threshold", cfg_audio.get("barge_cobra_threshold", 0.68)))
    80          self.voice_hold_ms = int(cfg_audio.get("barge_voice_hold_ms", cobra_cfg.get("hold_ms", 200)))
    81          self._cobra: Optional["pvcobra.Cobra"] = None
    82          self._cobra_rem = np.zeros(0, dtype=np.int16)
    83          self._cobra_last_prob: float = 0.0
    84          self._cobra_last_active_ms: int = 0
    85          self.cobra_enabled = False
    86          self._cobra_frame_len = 0
    87  
    88          if cobra_enabled_cfg:
    89              if pvcobra is None:
    90                  self.log.warning("Cobra VAD cerut dar library 'pvcobra' lipseÈ™te â€” revin la WebRTC VAD.")
    91              else:
    92                  ak = (
    93                      cobra_cfg.get("access_key")
    94                      or cfg_audio.get("cobra_access_key")
    95                      or os.getenv("PICOVOICE_ACCESS_KEY", "")
    96                  )
    97                  ak = (ak or "").strip()
    98                  if not ak:
    99                      self.log.warning("Cobra VAD: lipseÈ™te access_key (seteazÄƒ audio.cobra.access_key sau env PICOVOICE_ACCESS_KEY).")
   100                  else:
   101                      try:
   102                          cobra_kwargs = {"access_key": ak}
   103                          library_path = (cobra_cfg.get("library_path") or "").strip()
   104                          if library_path:
   105                              cobra_kwargs["library_path"] = library_path
   106                          model_path = (cobra_cfg.get("model_path") or "").strip()
   107                          if model_path:
   108                              cobra_kwargs["model_path"] = model_path
   109  
   110                          try:
   111                              self._cobra = pvcobra.create(**cobra_kwargs)
   112                          except TypeError as te:
   113                              if "model_path" in cobra_kwargs and "model_path" in str(te):
   114                                  self.log.warning("Cobra VAD: versiunea curentÄƒ nu acceptÄƒ model_path â€” folosesc modelul implicit.")
   115                                  cobra_kwargs.pop("model_path", None)
   116                                  self._cobra = pvcobra.create(**cobra_kwargs)
   117                              else:
   118                                  raise
   119                          self._cobra_frame_len = int(getattr(self._cobra, "frame_length", pvcobra.Cobra.frame_length))
   120                          cobra_sr = int(getattr(self._cobra, "sample_rate", pvcobra.Cobra.sample_rate))
   121                      except Exception as e:
   122                          self.log.warning(f"Cobra VAD nu poate fi iniÈ›ializat ({e}) â€” revin la WebRTC VAD.")
   123                          self._cobra = None
   124                      else:
   125                          if cobra_sr != self.sr:
   126                              self.log.warning(
   127                                  f"Cobra VAD cere {cobra_sr} Hz dar inputul foloseÈ™te {self.sr} Hz â€” dezactivez Cobra."
   128                              )
   129                              try:
   130                                  self._cobra.delete()
   131                              except Exception:
   132                                  pass
   133                              self._cobra = None
   134                          else:
   135                              self.cobra_enabled = True
   136  
   137          if not self.cobra_enabled:
   138              self.voice_hold_ms = int(cfg_audio.get("barge_voice_hold_ms", 200))
   139  
   140          # â€”â€”â€” Praguri temporale â€”â€”â€”
   141          self.min_voice_ms = int(cfg_audio.get("barge_min_voice_ms", 800))
   142          self.debounce_ms = int(cfg_audio.get("barge_debounce_ms", 150))
   143          self.cooldown_ms = int(cfg_audio.get("barge_cooldown_ms", 800))
   144          self.arm_after_ms = int(cfg_audio.get("barge_arm_after_ms", 400))
   145          self.voice_drop_ms = int(cfg_audio.get("barge_voice_drop_ms", self.block_ms))
   146          self._t0_ms = int(time.monotonic() * 1000)
   147          self._last_trigger_ms = 0
   148  
   149          # â€”â€”â€” Praguri spectrale/acustice â€”â€”â€”
   150          self.min_rms_dbfs = float(cfg_audio.get("barge_min_rms_dbfs", -28.0))
   151          self.highpass_hz = float(cfg_audio.get("barge_highpass_hz", 300.0))
   152          self.zcr_min = float(cfg_audio.get("barge_zcr_min", 0.05))
   153          self.zcr_max = float(cfg_audio.get("barge_zcr_max", 0.35))
   154  
   155          # â€”â€”â€” Device & VAD â€”â€”â€”
   156          self.dev_index = choose_input_device(
   157              prefer_echo_cancel=bool(cfg_audio.get("prefer_echo_cancel", True)),
   158              hint=str(cfg_audio.get("input_device_hint", "") or ""),
   159              logger=logger
   160          )
   161          vad_aggr = int(cfg_audio.get("vad_aggressiveness", 3))  # folosim VAD strict (3)
   162          self.vad = VAD(self.sr, vad_aggr, self.block_ms)
   163          self.q = queue.Queue()
   164          self._open_stream()
   165          self._voiced_ms = 0
   166          self._last_user_voice_ms: int = 0
   167          self.debug_meter = bool(cfg_audio.get("barge_debug_meter", False))
   168          self._debug_interval_ms = int(cfg_audio.get("barge_debug_interval_ms", 120))
   169          self._last_meter_ms: int = 0
   170  
   171          self.log.info(f"ğŸ¯ Barge-in inteligent: min_voice={self.min_voice_ms}ms, "
   172                        f"rms_thr={self.min_rms_dbfs}dB, hp={self.highpass_hz}Hz, "
   173                        f"zcr=[{self.zcr_min},{self.zcr_max}], "
   174                        f"cobra={'on' if self.cobra_enabled else 'off'} (thr={self.cobra_threshold})")
   175  
   176      def _open_stream(self):
   177          def cb(indata, frames, time_info, status):
   178              try:
   179                  self.q.put_nowait(indata.copy())
   180              except:
   181                  pass
   182          self.stream = sd.InputStream(
   183              channels=1, samplerate=self.sr, blocksize=self.block,
   184              dtype="float32", callback=cb, device=self.dev_index
   185          )
   186          self.stream.start()
   187  
   188      def _cobra_process(self, pcm_i16: np.ndarray) -> bool:
   189          """RuleazÄƒ Cobra pe cadre de frame_length È™i reÈ›ine probabilitatea curentÄƒ."""
   190          if not self.cobra_enabled or self._cobra is None or self._cobra_frame_len <= 0:
   191              return False
   192  
   193          data = pcm_i16
   194          if self._cobra_rem.size:
   195              data = np.concatenate((self._cobra_rem, data))
   196  
   197          idx = 0
   198          n = len(data)
   199          triggered = False
   200          now_ms = int(time.monotonic() * 1000)
   201  
   202          while idx + self._cobra_frame_len <= n:
   203              frame = data[idx:idx + self._cobra_frame_len]
   204              idx += self._cobra_frame_len
   205              try:
   206                  prob = float(self._cobra.process(frame.tolist()))
   207              except Exception as e:
   208                  self.log.warning(f"Cobra VAD process error: {e} â€” dezactivez Cobra.")
   209                  try:
   210                      self._cobra.delete()
   211                  except Exception:
   212                      pass
   213                  self._cobra = None
   214                  self.cobra_enabled = False
   215                  self._cobra_rem = np.zeros(0, dtype=np.int16)
   216                  return False
   217  
   218              self._cobra_last_prob = prob
   219              if prob >= self.cobra_threshold:
   220                  triggered = True
   221                  self._cobra_last_active_ms = now_ms
   222  
   223          self._cobra_rem = data[idx:]
   224          return triggered
   225  
   226      def _debug_meter(self, rms_db: float, cobra_prob: Optional[float], zcr: Optional[float], detected: bool, cobra_hit: bool) -> None:
   227          if not self.debug_meter:
   228              return
   229          now_ms = int(time.monotonic() * 1000)
   230          if (now_ms - self._last_meter_ms) < self._debug_interval_ms:
   231              return
   232          self._last_meter_ms = now_ms
   233  
   234          label = f"rms={rms_db:.1f}dB"
   235          value = 0.0
   236          if cobra_prob is not None and not math.isnan(cobra_prob):
   237              value = max(0.0, min(1.0, cobra_prob))
   238              label = f"cobra={cobra_prob:.2f}"
   239          else:
   240              span = max(5.0, abs(self.min_rms_dbfs))
   241              value = max(0.0, min(1.0, (rms_db - self.min_rms_dbfs) / span))
   242  
   243          bar_len = 20
   244          filled = min(bar_len, int(round(value * bar_len)))
   245          bar = "#" * filled + "-" * (bar_len - filled)
   246          zcr_str = f" zcr={zcr:.2f}" if zcr is not None else ""
   247          status = "Y" if detected else "n"
   248          src = "C" if cobra_hit else "V"
   249          self.log.info(f"[BARGE] |{bar}| {label}{zcr_str} det={status}/{src}")
   250  
   251      def _is_human_voice(self, pcm_i16: np.ndarray) -> bool:
   252          """
   253          VerificÄƒ dacÄƒ PCM-ul conÈ›ine voce umanÄƒ (nu zgomot/eco):
   254          1. RMS peste prag (vocea e mai tare decÃ¢t TTS leak)
   255          2. High-pass filter (eliminÄƒ bÄƒtÄƒi joase)
   256          3. Zero-crossing rate Ã®n interval vocii umane
   257          4. VAD confirmÄƒ speech
   258          """
   259          # 1) RMS check (anti-eco TTS)
   260          rms = _rms_dbfs(pcm_i16)
   261          if rms < self.min_rms_dbfs:
   262              self._debug_meter(rms, self._cobra_last_prob if self.cobra_enabled else None, None, False, False)
   263              return False
   264  
   265          # 2) High-pass filtering (anti-zgomot jos-frecvent)
   266          pcm_filtered = _highpass_filter(pcm_i16, self.highpass_hz, self.sr)
   267  
   268          now_ms = int(time.monotonic() * 1000)
   269  
   270          cobra_detected = False
   271          cobra_prob: Optional[float] = None
   272          if self.cobra_enabled and self._cobra is not None:
   273              cobra_detected = self._cobra_process(pcm_filtered)
   274              cobra_prob = self._cobra_last_prob
   275              if not cobra_detected and (now_ms - self._cobra_last_active_ms) <= self.voice_hold_ms:
   276                  cobra_detected = True
   277  
   278          # 3) Zero-crossing rate (anti-zgomot impulsiv)
   279          if not cobra_detected:
   280              zcr = _zero_crossing_rate(pcm_filtered)
   281              if not (self.zcr_min <= zcr <= self.zcr_max):
   282                  self._debug_meter(rms, cobra_prob, zcr, False, cobra_detected)
   283                  return False
   284          else:
   285              zcr = None
   286  
   287          # 4) VAD final check (Cobra sau WebRTC)
   288          if cobra_detected:
   289              detected = True
   290          else:
   291              pcm_bytes = struct.pack("<%dh" % len(pcm_filtered), *pcm_filtered)
   292              detected = self.vad.is_speech(pcm_bytes)
   293              if not detected and (now_ms - self._last_user_voice_ms) <= self.voice_hold_ms:
   294                  detected = True
   295  
   296          if detected:
   297              self._last_user_voice_ms = now_ms
   298          self._debug_meter(rms, cobra_prob, zcr, detected, cobra_detected)
   299          return detected
   300  
   301      def heard_speech(self, need_ms: int = None) -> bool:
   302          """
   303          ReturneazÄƒ True dacÄƒ a detectat voce umanÄƒ continuÄƒ >= need_ms.
   304          IgnorÄƒ zgomotele, bÄƒtÄƒile, ecoul TTS.
   305          """
   306          if need_ms is None:
   307              need_ms = self.min_voice_ms
   308  
   309          now_ms = int(time.monotonic() * 1000)
   310  
   311          # Arm-delay: ignorÄƒ totul la Ã®nceput (anti-scurgeri iniÈ›iale)
   312          if (now_ms - self._t0_ms) < self.arm_after_ms:
   313              try:
   314                  while True:
   315                      self.q.get_nowait()
   316              except queue.Empty:
   317                  pass
   318              return False
   319  
   320          # Debounce: evitÄƒ trigger repetat rapid
   321          if (now_ms - self._last_trigger_ms) < self.debounce_ms:
   322              return False
   323  
   324          # ProceseazÄƒ frame-uri pÃ¢nÄƒ la deadline scurt (20ms)
   325          deadline = time.time() + 0.02
   326          while time.time() < deadline:
   327              try:
   328                  block = self.q.get_nowait()
   329              except queue.Empty:
   330                  break
   331  
   332              pcm = np.clip(block[:, 0], -1, 1)
   333              pcm_i16 = (pcm * 32767.0).astype(np.int16)
   334  
   335              # VerificÄƒ dacÄƒ e voce umanÄƒ (nu zgomot/eco)
   336              if self._is_human_voice(pcm_i16):
   337                  self._voiced_ms = min(self._voiced_ms + self.block_ms, need_ms)
   338              else:
   339                  # Pierde progres gradual (nu reset instant) pentru drop-uri scurte
   340                  self._voiced_ms = max(0, self._voiced_ms - self.voice_drop_ms)
   341  
   342              # Trigger dacÄƒ voce continuÄƒ >= need_ms
   343              if self._voiced_ms >= need_ms:
   344                  now2 = int(time.monotonic() * 1000)
   345                  # Cooldown: evitÄƒ dublu-trigger
   346                  if (now2 - self._last_trigger_ms) >= self.cooldown_ms:
   347                      self._last_trigger_ms = now2
   348                      self._voiced_ms = 0
   349                      self.log.info(f"ğŸ¤ Barge-in: voce umanÄƒ detectatÄƒ ({need_ms}ms)")
   350                      return True
   351                  self._voiced_ms = 0
   352                  return False
   353  
   354          return False
   355  
   356      def close(self):
   357          try:
   358              self.stream.stop()
   359              self.stream.close()
   360          except Exception:
   361              pass
   362          if self._cobra is not None:
   363              try:
   364                  self._cobra.delete()
   365              except Exception:
   366                  pass
   367              self._cobra = None
   368  
   369      def user_is_speaking(self) -> bool:
   370          """IndicÄƒ dacÄƒ recent a fost detectatÄƒ voce umanÄƒ (folosit de FastExit)."""
   371          now_ms = int(time.monotonic() * 1000)
   372          if self.cobra_enabled and self._cobra_last_active_ms:
   373              if (now_ms - self._cobra_last_active_ms) <= self.voice_hold_ms:
   374                  return True
   375          return (now_ms - self._last_user_voice_ms) <= self.voice_hold_ms

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/devices.py =====
     1  # src/audio/devices.py
     2  from __future__ import annotations
     3  from typing import Optional, Tuple, List
     4  import sounddevice as sd
     5  
     6  def _match(hay: str, needle: str) -> bool:
     7      return (needle or "").lower() in (hay or "").lower()
     8  
     9  def list_input_devices() -> List[Tuple[int, str]]:
    10      try:
    11          devs = sd.query_devices()
    12      except Exception:
    13          return []
    14      out = []
    15      for i, d in enumerate(devs):
    16          if d.get("max_input_channels", 0) > 0:
    17              name = d.get("name", "")
    18              host = d.get("hostapi", None)
    19              out.append((i, name))
    20      return out
    21  
    22  def choose_input_device(
    23      prefer_echo_cancel: bool = True,
    24      hint: str = "",
    25      index: Optional[int] = None,
    26      logger=None
    27  ) -> Optional[int]:
    28      """ReturneazÄƒ indexul dispozitivului de intrare preferat.
    29         Prioritate: index explicit > nume "echo-cancel" > hint > default(None)
    30      """
    31      # 0) index explicit?
    32      if index is not None:
    33          if logger: logger.debug(f"ğŸ™ï¸ selectez input prin index forÈ›at: {index}")
    34          return index
    35  
    36      # 1) listÄƒ device-uri (pt. debug)
    37      devs = list_input_devices()
    38      if logger:
    39          if not devs:
    40              logger.warning("Nu pot interoga dispozitivele audio (sounddevice/PortAudio). Folosesc default OS.")
    41          else:
    42              names = " | ".join([f"[{i}] {n}" for i, n in devs])
    43              logger.debug(f"ğŸ” Input devices: {names}")
    44  
    45      # 2) echo-cancel dupÄƒ mai multe pattern-uri
    46      if prefer_echo_cancel and devs:
    47          keys = ["echo-cancel", "echo cancel", "cancelled", "ec_mic", "aec"]
    48          for i, n in devs:
    49              if any(_match(n, k) for k in keys):
    50                  if logger: logger.debug(f"ğŸ™ï¸ selectez input '{n}' (echo-cancel).")
    51                  return i
    52  
    53      # 3) dupÄƒ hint liber
    54      if hint and devs:
    55          for i, n in devs:
    56              if _match(n, hint):
    57                  if logger: logger.debug(f"ğŸ™ï¸ selectez input dupÄƒ hint '{hint}': {n}")
    58                  return i
    59  
    60      if logger: logger.debug("ğŸ™ï¸ folosesc input audio implicit (OS default).")
    61      return None

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/input.py =====
     1  # src/audio/input.py
     2  import queue, time, struct
     3  from pathlib import Path
     4  import numpy as np
     5  import sounddevice as sd
     6  import soundfile as sf
     7  
     8  from .devices import choose_input_device, list_input_devices
     9  from .vad import VAD
    10  from .processing import AudioEffects
    11  
    12  # Import opÈ›ional: nu crÄƒpa dacÄƒ nu existÄƒ webrtc AEC
    13  try:
    14      from .aec_webrtc import WebRTCAEC  # opÈ›ional
    15  except Exception:
    16      WebRTCAEC = None
    17  
    18  
    19  def _float_to_int16(audio_f32: np.ndarray) -> np.ndarray:
    20      audio_f32 = np.clip(audio_f32, -1.0, 1.0)
    21      return (audio_f32 * 32767.0).astype(np.int16)
    22  
    23  
    24  def record_until_silence(cfg_audio: dict, out_wav_path: Path, logger):
    25      """
    26      ÃnregistreazÄƒ mono 16kHz È™i se opreÈ™te dupÄƒ `silence_ms_to_end` ms de liniÈ™te
    27      (detectatÄƒ de VAD) sau dupÄƒ `max_record_seconds` (fallback).
    28  
    29      Anti-spam: dacÄƒ vocea cumulatÄƒ < `min_valid_seconds` -> NU salveazÄƒ fiÈ™ierul, Ã®ntoarce voice_sec.
    30  
    31      ReturneazÄƒ: (path, voice_seconds)
    32      """
    33      sr = int(cfg_audio["sample_rate"])
    34      block_ms = int(cfg_audio["block_ms"])              # 10/20/30 ms
    35      silence_ms_to_end = int(cfg_audio["silence_ms_to_end"])
    36      max_secs = int(cfg_audio["max_record_seconds"])
    37      min_valid_seconds = float(cfg_audio.get("min_valid_seconds", 0.5))
    38  
    39      assert block_ms in (10, 20, 30), "VAD frame must be 10/20/30 ms"
    40      block_size = int(sr * (block_ms / 1000.0))
    41  
    42      # â€”â€”â€” Audio Effects simple â€”â€”â€”
    43      effects = AudioEffects(
    44          ns=bool(cfg_audio.get("ns", True)),
    45          agc=bool(cfg_audio.get("agc", True)),
    46          hpf=bool(cfg_audio.get("hpf", True)),
    47      )
    48  
    49      # â€”â€”â€” AEC WebRTC (opÈ›ional, doar dacÄƒ aec_mode=webrtc È™i clasa existÄƒ) â€”â€”â€”
    50      aec = None
    51      if (str(cfg_audio.get("aec_mode", "system")).lower() == "webrtc") and WebRTCAEC:
    52          try:
    53              aec = WebRTCAEC(sample_rate=sr, frame_ms=block_ms)
    54              logger.info("ğŸ” WebRTC AEC activ (in-app).")
    55          except Exception as e:
    56              logger.warning(f"Nu pot porni WebRTC AEC: {e}. Continui fÄƒrÄƒ AEC.")
    57              aec = None
    58      else:
    59          # FoloseÈ™ti AEC de sistem (PulseAudio/pipewire echo-cancel) dacÄƒ e disponibil
    60          pass
    61  
    62      # â€”â€”â€” Device selection â€”â€”â€”
    63      dev_index = choose_input_device(
    64          prefer_echo_cancel=bool(cfg_audio.get("prefer_echo_cancel", True)),
    65          hint=str(cfg_audio.get("input_device_hint", "") or ""),
    66          index=(cfg_audio.get("input_device_index") if cfg_audio.get("input_device_index") not in (None, "") else None),
    67          logger=logger
    68      )
    69  
    70      q = queue.Queue()
    71      vad = VAD(sr, cfg_audio.get("vad_aggressiveness", 2), block_ms)
    72  
    73      logger.info(f"ğŸ¤ VorbeÈ™teâ€¦ (se opreÈ™te dupÄƒ {silence_ms_to_end}ms de liniÈ™te)")
    74      started = time.time()
    75      last_voice_ms = 0
    76      voiced_ms_total = 0       # â€” cumulÄƒm DOAR timpul de voce detectatÄƒ (anti-spam)
    77      collected = []
    78  
    79      def callback(indata, frames, time_info, status):
    80          if status:
    81              logger.debug(f"Audio status: {status}")
    82          q.put(indata.copy())
    83  
    84      with sd.InputStream(
    85          channels=1,
    86          samplerate=sr,
    87          blocksize=block_size,
    88          dtype="float32",
    89          callback=callback,
    90          device=dev_index  # <- poate fi None (default OS)
    91      ):
    92          while True:
    93              try:
    94                  block = q.get(timeout=0.5)  # float32 [-1,1], mono
    95              except queue.Empty:
    96                  if time.time() - started > max_secs:
    97                      break
    98                  continue
    99  
   100              pcm_i16 = _float_to_int16(block[:, 0])
   101  
   102              # AEC (opÈ›ional, dacÄƒ existÄƒ)
   103              if aec:
   104                  try:
   105                      pcm_i16 = aec.process_frame(pcm_i16)
   106                  except Exception:
   107                      pass
   108  
   109              # IgienÄƒ audio Ã®nainte de VAD
   110              pcm_i16 = effects.process_frame(pcm_i16)
   111  
   112              collected.append(pcm_i16)
   113  
   114              # VAD pe bytes little-endian
   115              pcm_bytes = struct.pack("<%dh" % len(pcm_i16), *pcm_i16)
   116              if vad.is_speech(pcm_bytes):
   117                  last_voice_ms = 0
   118                  voiced_ms_total += block_ms
   119              else:
   120                  last_voice_ms += block_ms
   121  
   122              if last_voice_ms >= silence_ms_to_end:
   123                  break
   124              if time.time() - started > max_secs:
   125                  break
   126  
   127      if aec:
   128          try:
   129              aec.close()
   130          except Exception:
   131              pass
   132  
   133      audio = np.concatenate(collected, axis=0) if collected else np.zeros(1, dtype=np.int16)
   134      voice_sec = voiced_ms_total / 1000.0
   135  
   136      # â€” dacÄƒ vocea efectivÄƒ este sub prag -> NU salvÄƒm nimic (anti-spam)
   137      if voice_sec < min_valid_seconds:
   138          logger.info(f"â­ï¸ Utterance prea scurt (voce ~{voice_sec:.2f}s < {min_valid_seconds:.2f}s) â€” ignor, nu salvez.")
   139          return str(out_wav_path), voice_sec
   140  
   141      out_wav_path.parent.mkdir(parents=True, exist_ok=True)
   142      sf.write(str(out_wav_path), audio, sr, subtype="PCM_16")
   143      dur = len(audio) / sr
   144      logger.info(f"âœ… Ãnregistrare salvatÄƒ: {out_wav_path} (audio ~{dur:.2f}s, voce ~{voice_sec:.2f}s)")
   145      return str(out_wav_path), voice_sec

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/monitors.py =====
     1  # src/audio/monitors.py
     2  from __future__ import annotations
     3  import sounddevice as sd
     4  
     5  def _match(hay: str, needle: str) -> bool:
     6      return needle.lower() in (hay or "").lower()
     7  
     8  def choose_monitor_device(hint: str = "", logger=None):
     9      try:
    10          devs = sd.query_devices()
    11      except Exception as e:
    12          if logger: logger.warning(f"Nu pot interoga device-urile: {e}")
    13          return None
    14      candidates = [(i, d) for i, d in enumerate(devs) if d.get("max_input_channels", 0) > 0]
    15      keys = []
    16      if hint: keys.append(hint)
    17      keys += ["monitor", "loopback", "stereo mix", "what u hear"]
    18  
    19      for i, d in candidates:
    20          name = (d.get("name") or "")
    21          if any(_match(name, k) for k in keys):
    22              if logger: logger.info(f"ğŸ” selectez monitor '{name}' (far-end pentru AEC)")
    23              return i
    24      if logger: logger.warning("âš ï¸ Nu am gÄƒsit monitor/loopback; AEC WebRTC va folosi far-end=0 (mai slab).")
    25      return None

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/output.py =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/processing.py =====
     1  # src/audio/processing.py
     2  from __future__ import annotations
     3  from typing import Optional
     4  import numpy as np
     5  
     6  class AudioEffects:
     7      """
     8      NS/AGC/HPF simple, per-frame (int16).
     9      - HPF: DC blocker (y[n] = x[n] - x[n-1] + r*y[n-1], râ‰ˆ0.995)
    10      - NS: noise gate blÃ¢nd (~-50 dBFS)
    11      - AGC: nivelare cÄƒtre un RMS-È›intÄƒ, cu clamp pe factor
    12      Nu introduce dependenÈ›e grele; latenÈ›Äƒ ~0.
    13      """
    14  
    15      def __init__(self, ns: bool = True, agc: bool = True, hpf: bool = True):
    16          self.ns = ns
    17          self.agc = agc
    18          self.hpf = hpf
    19          # state pentru HPF
    20          self._x1 = 0.0
    21          self._y1 = 0.0
    22          self._r = 0.995  # coef. DC blocker
    23  
    24          # AGC
    25          self._target_rms = 0.05   # ~-26 dBFS È›intÄƒ â€confortâ€
    26          self._agc_max_gain = 6.0  # max 6x (~+15.6 dB)
    27          self._agc_min_gain = 0.5  # -6 dB
    28          self._agc_smooth = 0.2    # smoothing (0..1), 1 = instant
    29  
    30          self._gain = 1.0
    31  
    32      def _apply_hpf(self, x: np.ndarray) -> np.ndarray:
    33          # int16 -> float32
    34          xf = x.astype(np.float32) / 32768.0
    35          y = np.empty_like(xf)
    36          x1 = self._x1
    37          y1 = self._y1
    38          r = self._r
    39          for i in range(len(xf)):
    40              yn = xf[i] - x1 + r * y1
    41              y[i] = yn
    42              x1 = xf[i]
    43              y1 = yn
    44          self._x1, self._y1 = x1, y1
    45          # back to int16
    46          y = np.clip(y * 32768.0, -32768, 32767).astype(np.int16)
    47          return y
    48  
    49      def _apply_ns(self, x: np.ndarray) -> np.ndarray:
    50          # noise gate simplu: dacÄƒ RMS < thr, atenuÄƒm cu -20 dB
    51          xf = x.astype(np.float32) / 32768.0
    52          rms = float(np.sqrt(np.mean(xf * xf)) + 1e-9)
    53          thr = 0.003  # ~ -50 dBFS
    54          if rms < thr:
    55              xf *= 0.1  # -20 dB
    56          y = np.clip(xf * 32768.0, -32768, 32767).astype(np.int16)
    57          return y
    58  
    59      def _apply_agc(self, x: np.ndarray) -> np.ndarray:
    60          xf = x.astype(np.float32) / 32768.0
    61          rms = float(np.sqrt(np.mean(xf * xf)) + 1e-9)
    62          if rms > 0:
    63              desired_gain = self._target_rms / rms
    64              desired_gain = float(np.clip(desired_gain, self._agc_min_gain, self._agc_max_gain))
    65              # smooth
    66              self._gain = (1 - self._agc_smooth) * self._gain + self._agc_smooth * desired_gain
    67          y = np.clip(xf * self._gain, -1.0, 1.0)
    68          return (y * 32768.0).astype(np.int16)
    69  
    70      def process_frame(self, pcm_i16: np.ndarray) -> np.ndarray:
    71          y = pcm_i16
    72          try:
    73              if self.hpf:
    74                  y = self._apply_hpf(y)
    75              if self.ns:
    76                  y = self._apply_ns(y)
    77              if self.agc:
    78                  y = self._apply_agc(y)
    79          except Exception:
    80              # fail-safe: dacÄƒ ceva nu merge, trecem frame-ul nemodificat
    81              return pcm_i16
    82          return y

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/reverse_capture.py =====
     1  # src/audio/reverse_capture.py
     2  from __future__ import annotations
     3  import sounddevice as sd
     4  import numpy as np, queue
     5  
     6  class ReverseCapture:
     7      def __init__(self, device_index, samplerate, block_size, logger=None):
     8          self.device = device_index
     9          self.sr = samplerate
    10          self.block = block_size
    11          self.q = queue.Queue(maxsize=100)
    12          self.logger = logger
    13          self.stream = None
    14  
    15      def start(self):
    16          def cb(indata, frames, time_info, status):
    17              if status and self.logger:
    18                  self.logger.debug(f"Monitor status: {status}")
    19              try:
    20                  self.q.put_nowait(indata.copy())
    21              except queue.Full:
    22                  try: self.q.get_nowait()
    23                  except: pass
    24                  self.q.put_nowait(indata.copy())
    25  
    26          self.stream = sd.InputStream(
    27              channels=1, samplerate=self.sr, blocksize=self.block,
    28              dtype="float32", callback=cb, device=self.device
    29          )
    30          self.stream.start()
    31  
    32      def get_frame_i16(self):
    33          try:
    34              block = self.q.get_nowait()
    35              return np.clip(block[:, 0] * 32767.0, -32768, 32767).astype(np.int16)
    36          except queue.Empty:
    37              return np.zeros(self.block, dtype=np.int16)
    38  
    39      def stop(self):
    40          try:
    41              if self.stream:
    42                  self.stream.stop()
    43                  self.stream.close()
    44          except Exception:
    45              pass

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/vad.py =====
     1  
     2  import warnings
     3  warnings.filterwarnings(
     4      "ignore",
     5      message=r"pkg_resources is deprecated as an API.*",
     6      category=UserWarning,
     7  )
     8  import webrtcvad
     9  
    10  
    11  
    12  
    13  class VAD:
    14      def __init__(self, sample_rate: int, aggressiveness: int = 2, frame_ms: int = 30):
    15          assert frame_ms in (10, 20, 30), "VAD frame must be 10/20/30 ms"
    16          self.sr = sample_rate
    17          self.frame_ms = frame_ms
    18          self.vad = webrtcvad.Vad(aggressiveness)
    19  
    20      def is_speech(self, pcm_bytes: bytes) -> bool:
    21          return self.vad.is_speech(pcm_bytes, self.sr)

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/audio/wake_porcupine.py =====
     1  # src/audio/wake_porcupine.py
     2  from __future__ import annotations
     3  import queue, time
     4  from typing import Optional
     5  import numpy as np
     6  import sounddevice as sd
     7  
     8  from .devices import choose_input_device
     9  
    10  def wait_for_wake(
    11      cfg_audio: dict,
    12      access_key: str,
    13      keyword_path: str,
    14      sensitivity: float = 0.6,
    15      logger=None,
    16      timeout_seconds: Optional[float] = None,
    17  ) -> bool:
    18      """
    19      BlocheazÄƒ pÃ¢nÄƒ detecteazÄƒ wake-word cu Porcupine.
    20      ReturneazÄƒ True dacÄƒ s-a detectat, False pe eroare/timeout.
    21      """
    22      try:
    23          import pvporcupine as pv
    24      except Exception as e:
    25          if logger: logger.error(f"Porcupine indisponibil: {e}")
    26          return False
    27  
    28      porcupine = None
    29      stream = None
    30      q = queue.Queue(maxsize=16)
    31  
    32      try:
    33          porcupine = pv.create(
    34              access_key=access_key,
    35              keyword_paths=[keyword_path],
    36              sensitivities=[float(sensitivity)],
    37          )
    38          sr = porcupine.sample_rate
    39          frame_len = porcupine.frame_length
    40  
    41          dev_index = choose_input_device(
    42              prefer_echo_cancel=bool(cfg_audio.get("prefer_echo_cancel", True)),
    43              hint=str(cfg_audio.get("input_device_hint", "") or ""),
    44              logger=logger
    45          )
    46  
    47          if logger:
    48              logger.info(f"ğŸ§ Standby (Porcupine) â€” sr={sr}, frame={frame_len}, sens={sensitivity}")
    49  
    50          def cb(indata, frames, time_info, status):
    51              # indata: int16 mono (dacÄƒ cerem dtype="int16")
    52              if status and logger:
    53                  logger.debug(f"Porcupine input status: {status}")
    54              try:
    55                  q.put_nowait(indata.copy())
    56              except queue.Full:
    57                  try: q.get_nowait()
    58                  except Exception: pass
    59                  try: q.put_nowait(indata.copy())
    60                  except Exception: pass
    61  
    62          stream = sd.InputStream(
    63              channels=1,
    64              samplerate=sr,
    65              blocksize=frame_len,
    66              dtype="int16",
    67              callback=cb,
    68              device=dev_index
    69          )
    70          stream.start()
    71  
    72          t0 = time.time()
    73          while True:
    74              try:
    75                  block = q.get(timeout=0.5)  # shape: (frame_len, 1) int16
    76              except queue.Empty:
    77                  if timeout_seconds and (time.time() - t0) > timeout_seconds:
    78                      if logger: logger.info("â³ Porcupine timeout Ã®n standby.")
    79                      return False
    80                  continue
    81  
    82              # aplatizeazÄƒ pe 1-D
    83              if block.ndim == 2:
    84                  pcm_i16 = block[:, 0]
    85              else:
    86                  pcm_i16 = block
    87  
    88              # Porcupine vrea int16 1-D de lungime frame_len
    89              if len(pcm_i16) != frame_len:
    90                  # Ã®n cazuri rare, re-sample blocul
    91                  pcm_i16 = pcm_i16[:frame_len].astype("int16")
    92  
    93              res = porcupine.process(pcm_i16)
    94              if res >= 0:
    95                  if logger: logger.info("ğŸ”” Wake (Porcupine) detectatÄƒ.")
    96                  return True
    97  
    98      except KeyboardInterrupt:
    99          if logger: logger.info("Stop (CTRL+C).")
   100          return False
   101      except Exception as e:
   102          if logger: logger.error(f"Porcupine runtime error: {e}")
   103          return False
   104      finally:
   105          try:
   106              if stream:
   107                  stream.stop(); stream.close()
   108          except Exception:
   109              pass
   110          try:
   111              if porcupine:
   112                  porcupine.delete()
   113          except Exception:
   114              pass

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/core/config.py =====
     1  import yaml
     2  from pathlib import Path
     3  from typing import Dict, Any
     4  import os, re
     5  
     6  # Suntem Ã®n src/core/config.py -> urcÄƒm douÄƒ nivele: core -> src -> (root)
     7  ROOT = Path(__file__).resolve().parents[2]
     8  CFG = ROOT / "configs"
     9  
    10  # --- interpolare ENV pentru stringuri din YAML: ${VAR} sau $VAR ---
    11  _ENV_VAR = re.compile(r"\$\{([^}]+)\}|\$([A-Za-z_][A-Za-z0-9_]*)")
    12  
    13  def _expand_env_in_obj(obj):
    14      if isinstance(obj, dict):
    15          return {k: _expand_env_in_obj(v) for k, v in obj.items()}
    16      if isinstance(obj, list):
    17          return [_expand_env_in_obj(v) for v in obj]
    18      if isinstance(obj, str):
    19          def repl(m):
    20              var = m.group(1) or m.group(2)
    21              return os.getenv(var, "")
    22          return _ENV_VAR.sub(repl, obj)
    23      return obj
    24  
    25  def load_yaml(name: str):
    26      # name = "audio.yaml", "asr.yaml", etc. (NU cu "configs/")
    27      with open(CFG / name, "r", encoding="utf-8") as f:
    28          data = yaml.safe_load(f)
    29      return _expand_env_in_obj(data)
    30  
    31  def load_all() -> Dict[str, Any]:
    32      raw = {
    33          "audio": load_yaml("audio.yaml"),
    34          "asr":   load_yaml("asr.yaml"),
    35          "llm":   load_yaml("llm.yaml"),
    36          "tts":   load_yaml("tts.yaml"),
    37          "wake":  load_yaml("wake.yaml"),
    38          "route": load_yaml("routing.yaml"),
    39          "paths": {
    40              "data": str((ROOT / "data").absolute()),
    41              "models": str((ROOT / "models").absolute()),
    42          }
    43      }
    44      from src.core.config_schema import validate_all
    45      return validate_all(raw)

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/core/config_schema.py =====
     1  # src/core/config_schema.py
     2  from pydantic import BaseModel, Field, field_validator, ConfigDict
     3  from typing import Optional, List, Dict, Any
     4  
     5  class AudioCfg(BaseModel):
     6      model_config = ConfigDict(extra="allow", protected_namespaces=())
     7      sample_rate: int = Field(16000, ge=8000, le=48000)
     8      block_ms: int = Field(20)
     9      vad_aggressiveness: int = Field(2, ge=0, le=3)
    10      silence_ms_to_end: int = Field(500, ge=100, le=5000)
    11      max_record_seconds: int = Field(15, ge=1, le=300)
    12      session_idle_seconds: Optional[int] = Field(12, ge=3, le=120)
    13      min_valid_seconds: Optional[float] = Field(0.5, ge=0.0, le=3.0)
    14  
    15      @field_validator("block_ms")
    16      @classmethod
    17      def check_block_ms(cls, v: int):
    18          if v not in (10, 20, 30):
    19              raise ValueError("audio.block_ms must be one of: 10, 20, 30")
    20          return v
    21  
    22  class ASRCfg(BaseModel):
    23      model_config = ConfigDict(protected_namespaces=())
    24      provider: str = Field("faster")                 # faster | openai
    25      model_size: str = Field("base")
    26      compute_type: Optional[str] = Field("int8")     # int8 | float16 | int8_float16
    27      device: str = Field("cpu")                      # cpu | cuda
    28      beam_size: Optional[int] = Field(1, ge=1, le=8)
    29      force_language: Optional[str] = None
    30      vad_min_silence_ms: int = Field(300, ge=100, le=1500)
    31  
    32  class LLMCfg(BaseModel):
    33      provider: str = Field("ollama")
    34      host: str = Field("http://127.0.0.1:11434")
    35      model: str = Field("llama3.2")
    36      max_tokens: int = Field(120, ge=16, le=4096)
    37      temperature: float = Field(0.4, ge=0.0, le=1.5)
    38      language_policy: Optional[str] = Field("auto")
    39      system_prompt: Optional[str] = ""
    40      default_mode: Optional[str] = Field("precise")
    41      strict_facts: Optional[bool] = Field(True)
    42  
    43  class PiperCfg(BaseModel):
    44      model_config = ConfigDict(protected_namespaces=(), extra="allow")
    45      exe: Optional[str] = None
    46      model_ro: Optional[str] = None
    47      config_ro: Optional[str] = None
    48      model_en: Optional[str] = None
    49      config_en: Optional[str] = None
    50      speaker_id: Optional[int] = None
    51      length_scale: float = 1.0
    52      noise_scale: float = 0.667
    53      noise_w: float = 0.8
    54      sentence_silence_ms: int = 80
    55  
    56  class TTSCfg(BaseModel):
    57      model_config = ConfigDict(extra="allow", protected_namespaces=())
    58      backend: str = Field("pyttsx3")
    59      rate: int = Field(180, ge=60, le=400)
    60      volume: float = Field(0.9, ge=0.0, le=1.0)
    61      voice_ro_hint: Optional[str] = Field("ro")
    62      voice_en_hint: Optional[str] = Field("en")
    63      piper: Optional[PiperCfg] = None
    64  
    65  class PorcupineCfg(BaseModel):
    66      enabled: bool = False
    67      access_key: Optional[str] = None
    68      ppn_path: Optional[str] = None
    69      sensitivity: float = 0.6
    70      lang_hint: Optional[str] = Field("auto")  # "auto" | "en" | "ro"
    71  
    72  class WakeCfg(BaseModel):
    73      wake_phrases: List[str]
    74      acknowledgement: Dict[str, str]
    75      porcupine: Optional[PorcupineCfg] = None
    76  
    77  class RouteCfg(BaseModel):
    78      rules: List[Dict[str, Any]] = []
    79  
    80  class PathsCfg(BaseModel):
    81      data: str
    82      models: str
    83  
    84  class AppCfg(BaseModel):
    85      audio: AudioCfg
    86      asr: ASRCfg
    87      llm: LLMCfg
    88      tts: TTSCfg
    89      wake: WakeCfg
    90      route: RouteCfg
    91      paths: PathsCfg
    92  
    93  def validate_all(raw: dict) -> dict:
    94      model = AppCfg(**raw)
    95      return model.model_dump()

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/core/fast_exit.py =====
     1  from __future__ import annotations
     2  import time
     3  from rapidfuzz import fuzz
     4  from typing import Any, Optional
     5  from src.utils.textnorm import normalize_text
     6  
     7  class FastExit:
     8      """
     9      DetecteazÄƒ pe *parÈ›iale ASR* expresii de tip "ok bye"/"pa" È™i opreÈ™te imediat
    10      TTS + LLM stream, apoi trece Ã®n STANDBY. Non-intruziv, cu debounce È™i (opÈ›ional)
    11      verificare cÄƒ vorbeÈ™te userul (nu ecoul TTS) via barge listener.
    12      """
    13  
    14      def __init__(
    15          self,
    16          tts: Any,
    17          llm: Any,
    18          state: Any,
    19          logger: Any,
    20          cfg: dict,
    21          barge: Optional[Any] = None,
    22      ):
    23          self.tts = tts
    24          self.llm = llm
    25          self.state = state
    26          self.log = logger
    27  
    28          self.enabled = bool(cfg.get("enabled", True))
    29          self.phrases = [p.lower() for p in cfg.get("phrases", [])]
    30          self.fuzzy = int(cfg.get("fuzzy", 90))
    31          self.debounce_ms = int(cfg.get("debounce_ms", 120))
    32          self.min_chars = int(cfg.get("min_chars", 2))
    33          self.confirm_tts = cfg.get("confirm_tts", "See you later!")
    34          self.use_barge = bool(cfg.get("use_barge_check", True))
    35          self.barge = barge
    36  
    37          self._last_hit_ms = 0
    38          self._aborted = False
    39  
    40      # â€”â€”â€” API simplu pentru orchestrator â€”â€”â€”
    41      def reset(self):
    42          self._aborted = False
    43  
    44      def pending(self) -> bool:
    45          """DacÄƒ e True, orice stream TTS/LLM ar trebui sÄƒ se opreascÄƒ."""
    46          return self._aborted
    47  
    48      # â€”â€”â€” Callbacks â€”â€”â€”
    49      def on_partial(self, text: str) -> bool:
    50          """
    51          Ãntoarce True dacÄƒ a declanÈ™at exitul (evenimentul a fost "consumat"),
    52          altfel False (lasÄƒ pipeline-ul sÄƒ continue normal).
    53          """
    54          if not self.enabled or not text:
    55              return False
    56  
    57          now = time.time() * 1000
    58          if (now - self._last_hit_ms) < self.debounce_ms:
    59              return False
    60  
    61          s = normalize_text(text).lower().strip()
    62          if len(s) < self.min_chars:
    63              return False
    64  
    65          # EvitÄƒ trigger pe ecou dacÄƒ ai barge-in detector (near-end only)
    66          if self.use_barge and self.barge and hasattr(self.barge, "user_is_speaking"):
    67              try:
    68                  if not self.barge.user_is_speaking():
    69                      return False
    70              except Exception:
    71                  pass
    72  
    73          for target in self.phrases:
    74              if s == target or fuzz.ratio(s, target) >= self.fuzzy:
    75                  self._last_hit_ms = now
    76                  self._trigger_exit(s)
    77                  return True
    78          return False
    79  
    80      def on_final(self, text: str) -> bool:
    81          """RecicleazÄƒ aceeaÈ™i logicÄƒ È™i pe transcriptul final (fallback)."""
    82          return self.on_partial(text)
    83  
    84      # â€”â€”â€” PoÈ›i apela manual pentru test â€”â€”â€”
    85      def trigger_exit(self, reason: str = "manual"):
    86          self._trigger_exit(reason)
    87  
    88      # â€”â€”â€” Intern â€”â€”â€”
    89      def _trigger_exit(self, matched: str):
    90          if self._aborted:
    91              return
    92          self._aborted = True
    93          try:
    94              self.log.info(f"[FAST_EXIT] Triggered by: '{matched}'")
    95          except Exception:
    96              pass
    97  
    98          # 1) OpreÈ™te orice audio/generare
    99          for obj in (self.tts, self.llm):
   100              for fn_name in ("stop", "cancel_stream", "cancel", "abort"):
   101                  fn = getattr(obj, fn_name, None)
   102                  if callable(fn):
   103                      try:
   104                          fn()
   105                      except Exception as e:
   106                          try:
   107                              self.log.warning(f"[FAST_EXIT] {fn_name} error: {e}")
   108                          except Exception:
   109                              pass
   110  
   111          # 2) Feedback auditiv minimal (opÈ›ional)
   112          if self.confirm_tts and hasattr(self.tts, "say") and callable(self.tts.say):
   113              try:
   114                  self.tts.say(self.confirm_tts)
   115              except Exception:
   116                  pass
   117  
   118          # 3) Treci Ã®n STANDBY
   119          # PreferÄƒ un setter dedicat; altfel Ã®ncearcÄƒ fallback.
   120          for setter in ("set_standby", "to_standby", "go_standby"):
   121              s = getattr(self.state, setter, None)
   122              if callable(s):
   123                  try:
   124                      s()
   125                      return
   126                  except Exception:
   127                      pass
   128          # Fallback hard dacÄƒ foloseÈ™ti enum BotState
   129          try:
   130              from src.core.states import BotState
   131              self.state = BotState.STANDBY
   132          except Exception:
   133              pass

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/core/health.py =====
     1  # src/core/health.py
     2  from __future__ import annotations
     3  import os, shutil
     4  from typing import Dict, Tuple
     5  from src.audio.devices import list_input_devices, choose_input_device
     6  
     7  def _yes(b): return "âœ…" if b else "âŒ"
     8  
     9  def run_health_checks(cfg: Dict, logger) -> Tuple[int, int]:
    10      """ReturneazÄƒ (warn_count, err_count). LogheazÄƒ un sumar drÄƒguÈ› Ã®n consolÄƒ."""
    11      warns = errs = 0
    12      logger.info("ğŸ©º  Health check â€” pornire")
    13  
    14      # Piper
    15      tts = cfg.get("tts", {})
    16      p = (tts.get("piper") or {})
    17      exe = (p.get("exe") or shutil.which("piper"))
    18      if exe and os.path.exists(exe):
    19          logger.info(f"  {_yes(True)} Piper exe: {exe}")
    20      else:
    21          warns += 1
    22          logger.warning(f"  {_yes(False)} Piper nu a fost gÄƒsit (exe={exe}). DacÄƒ vrei voce umanÄƒ, instaleazÄƒ piper-tts.")
    23  
    24      # Modele Piper
    25      for lang, mk, ck in [
    26          ("ro", p.get("model_ro"), p.get("config_ro")),
    27          ("en", p.get("model_en"), p.get("config_en")),
    28      ]:
    29          if mk and os.path.exists(mk):
    30              logger.info(f"  {_yes(True)} Piper model [{lang}]: {mk}")
    31          else:
    32              warns += 1
    33              logger.warning(f"  {_yes(False)} Piper model [{lang}] lipsÄƒ sau cale greÈ™itÄƒ: {mk}")
    34          if ck and os.path.exists(ck):
    35              logger.info(f"     {_yes(True)} config: {ck}")
    36          else:
    37              logger.info(f"     â„¹ï¸ config: {ck or 'â€”'}")
    38  
    39      # Player audio
    40      paplay = shutil.which("paplay")
    41      aplay = shutil.which("aplay")
    42      if paplay:
    43          logger.info(f"  {_yes(True)} Player: paplay ({paplay})")
    44      elif aplay:
    45          logger.info(f"  {_yes(True)} Player: aplay ({aplay})")
    46      else:
    47          warns += 1
    48          logger.warning(f"  {_yes(False)} FÄƒrÄƒ paplay/aplay â€” voi Ã®ncerca fallback Python (sounddevice).")
    49  
    50      # Dispozitive intrare & selecÈ›ia curentÄƒ
    51      devs = list_input_devices()
    52      if not devs:
    53          warns += 1
    54          logger.warning("  âŒ Nu pot interoga dispozitivele audio â€” merg pe OS default.")
    55      else:
    56          # Ã®ncearcÄƒ sÄƒ â€alegiâ€ ce ar alege app-ul
    57          try:
    58              idx = choose_input_device(
    59                  prefer_echo_cancel=bool(cfg["audio"].get("prefer_echo_cancel", True)),
    60                  hint=str(cfg["audio"].get("input_device_hint", "") or ""),
    61                  logger=logger
    62              )
    63          except Exception:
    64              idx = None
    65          pretty = " | ".join([f"[{i}] {n}" + (" â˜…" if idx == i else "") for i, n in devs])
    66          logger.info(f"  ğŸ™ï¸ Input devices: {pretty or 'â€”'}")
    67  
    68      # Parametri audio de bazÄƒ
    69      a = cfg.get("audio", {})
    70      logger.info(f"  ğŸ”§ Audio: sr={a.get('sample_rate')}Hz, block={a.get('block_ms')}ms, vad={a.get('vad_aggressiveness')}")
    71  
    72      logger.info(f"ğŸ©º  Health check â€” gata (warns={warns}, errors={errs})")
    73      return warns, errs

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/core/logger.py =====
     1  import logging, os, sys
     2  from logging.handlers import RotatingFileHandler
     3  
     4  TRACE_LEVEL = 5
     5  logging.addLevelName(TRACE_LEVEL, "TRACE")
     6  
     7  def _trace(self, msg, *args, **kwargs):
     8      if self.isEnabledFor(TRACE_LEVEL):
     9          self._log(TRACE_LEVEL, msg, args, **kwargs)
    10  
    11  logging.Logger.trace = _trace  # type: ignore[attr-defined]
    12  
    13  class _Color:
    14      MAP = {
    15          "TRACE": "\033[38;5;244m",
    16          "DEBUG": "\033[36m",
    17          "INFO":  "\033[32m",
    18          "WARNING":"\033[33m",
    19          "ERROR": "\033[31m",
    20          "CRITICAL":"\033[35m",
    21      }
    22      END = "\033[0m"
    23  
    24  class ColorFormatter(logging.Formatter):
    25      def format(self, record: logging.LogRecord) -> str:
    26          level = record.levelname
    27          color = _Color.MAP.get(level, "")
    28          end = _Color.END if color else ""
    29          record.levelname = f"{color}{level}{end}"
    30          return super().format(record)
    31  
    32  def _parse_level(name: str) -> int:
    33      name = (name or "").upper().strip()
    34      return {
    35          "TRACE": TRACE_LEVEL, "DEBUG": logging.DEBUG, "INFO": logging.INFO,
    36          "WARNING": logging.WARNING, "ERROR": logging.ERROR, "CRITICAL": logging.CRITICAL
    37      }.get(name, logging.INFO)
    38  
    39  def setup_logger(name: str = "bot"):
    40      level = _parse_level(os.getenv("LOG_LEVEL", "INFO"))
    41  
    42      logger = logging.getLogger(name)
    43      logger.setLevel(level)
    44      logger.propagate = False
    45  
    46      fmt = "%(asctime)s | %(levelname)s | %(name)s | %(message)s"
    47      datefmt = "%H:%M:%S"
    48  
    49      # Console
    50      ch = logging.StreamHandler(sys.stdout)
    51      ch.setLevel(level)
    52      ch.setFormatter(ColorFormatter(fmt=fmt, datefmt=datefmt))
    53      logger.addHandler(ch)
    54  
    55      # File (rotativ), dacÄƒ vrei log pe disc
    56      log_dir = os.getenv("LOG_DIR", "").strip()
    57      if log_dir:
    58          os.makedirs(log_dir, exist_ok=True)
    59          fh = RotatingFileHandler(os.path.join(log_dir, "app.log"), maxBytes=5_000_000, backupCount=3, encoding="utf-8")
    60          fh.setLevel(level)
    61          fh.setFormatter(logging.Formatter(fmt=fmt, datefmt=datefmt))
    62          logger.addHandler(fh)
    63  
    64      logger.debug("Logger ready (level=%s)", logging.getLevelName(level))
    65      return logger

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/core/states.py =====
     1  from enum import Enum, auto
     2  
     3  class BotState(Enum):
     4      LISTENING = auto()
     5      THINKING  = auto()
     6      SPEAKING  = auto()

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/core/wake.py =====
     1  # src/core/wake.py
     2  from typing import List, Optional, Tuple, Dict, Any
     3  from rapidfuzz import fuzz
     4  from src.utils.textnorm import normalize_text
     5  
     6  class _FuzzyWake:
     7      def __init__(self, phrases: List[str], threshold: int = 72):
     8          self.raw = list(phrases or [])
     9          self.norm = [normalize_text(p) for p in (phrases or [])]
    10          self.threshold = int(threshold)
    11  
    12      def match(self, user_text: str) -> Optional[str]:
    13          t = normalize_text(user_text)
    14          if not t:
    15              return None
    16          best: Tuple[str, int] = ("", -1)
    17          for raw, n in zip(self.raw, self.norm):
    18              score = fuzz.partial_ratio(n, t)
    19              if score > best[1]:
    20                  best = (raw, score)
    21          return best[0] if best[1] >= self.threshold else None
    22  
    23      def debug_scores(self, user_text: str):
    24          t = normalize_text(user_text or "")
    25          return {raw: fuzz.partial_ratio(n, t) for raw, n in zip(self.raw, self.norm)}
    26  
    27  class WakeDetector:
    28      """
    29      Facade peste mai multe motoare:
    30        - engine = 'asr'       -> fuzzy match pe text (ce aveai deja)
    31        - engine = 'porcupine' -> KWS offline, direct pe WAV (fÄƒrÄƒ ASR)
    32      """
    33      def __init__(self, cfg: Dict[str, Any], logger=None):
    34          self.cfg = cfg or {}
    35          self.log = logger
    36          self.engine = (self.cfg.get("engine") or "asr").lower()
    37          self.fuzzy = _FuzzyWake(self.cfg.get("wake_phrases") or [], threshold=int(self.cfg.get("threshold", 72)))
    38          self.porc = None
    39  
    40          if self.engine == "porcupine":
    41              try:
    42                  from src.wake.porcupine_engine import PorcupineWake
    43                  pcfg = self.cfg.get("porcupine") or {}
    44                  self.porc = PorcupineWake(
    45                      access_key=pcfg.get("access_key", ""),
    46                      keyword_paths=pcfg.get("keyword_paths"),
    47                      keywords=pcfg.get("keywords"),
    48                      sensitivities=pcfg.get("sensitivities"),
    49                      logger=logger,
    50                  )
    51              except Exception as e:
    52                  if logger: logger.error(f"Porcupine indisponibil: {e}. Revin pe engine=asr.")
    53                  self.engine = "asr"
    54                  self.porc = None
    55  
    56      # pentru engine=asr
    57      def match(self, user_text: str) -> Optional[str]:
    58          return self.fuzzy.match(user_text)
    59  
    60      def debug_scores(self, user_text: str):
    61          return self.fuzzy.debug_scores(user_text)
    62  
    63      # pentru engine=porcupine
    64      def detect_in_wav(self, wav_path: str) -> Optional[str]:
    65          if self.engine == "porcupine" and self.porc:
    66              return self.porc.detect_in_wav(wav_path)
    67          return None
    68  
    69      def close(self):
    70          try:
    71              if self.porc:
    72                  self.porc.close()
    73          except Exception:
    74              pass

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/llm/__init__.py =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/llm/engine.py =====
     1  # src/llm/engine.py
     2  from __future__ import annotations
     3  from typing import Dict, Optional
     4  import os, requests, json
     5  from src.telemetry.metrics import observe_hist, llm_latency, llm_first_token_latency, wrap_stream_for_first_token
     6  
     7  class LLMLocal:
     8      def __init__(self, cfg: Dict, logger):
     9          self.cfg = cfg or {}
    10          self.log = logger
    11  
    12          provider = (self.cfg.get("provider") or self.cfg.get("backend") or "rule").lower()
    13          if provider == "echo":
    14              provider = "rule"
    15          self.provider = provider
    16  
    17          self.system = self.cfg.get("system_prompt", "")
    18          self.host = self.cfg.get("host", "http://localhost:11434")
    19          self.model = self.cfg.get("model", "llama3.2")
    20          self.max_tokens = int(self.cfg.get("max_tokens", 120))
    21          self.temperature = float(self.cfg.get("temperature", 0.4))
    22  
    23          self.default_mode = (self.cfg.get("default_mode") or "precise").lower()
    24          self.strict_facts = bool(self.cfg.get("strict_facts", True))
    25  
    26          self._openai = None
    27          if self.provider == "openai":
    28              try:
    29                  from openai import OpenAI
    30                  self._openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    31              except Exception as e:
    32                  self.log.error(f"OpenAI client indisponibil: {e}. Revin pe 'rule'.")
    33                  self.provider = "rule"
    34  
    35          self.log.info(f"LLM provider activ: {self.provider}")
    36  
    37      def generate(self, user_text: str, lang_hint: str = "en", mode: Optional[str] = None) -> str:
    38          mode = (mode or self.default_mode).lower()
    39          with observe_hist(llm_latency):
    40              if self.provider == "rule":
    41                  return self._rule_based(user_text, lang_hint)
    42              if self.provider == "ollama":
    43                  return self._ollama_http(user_text, lang_hint, mode=mode)
    44              if self.provider == "openai" and self._openai:
    45                  return self._openai_chat(user_text, lang_hint)
    46              return "No LLM provider configured."
    47  
    48      def generate_stream(self, user_text: str, lang_hint: str = "en", mode: Optional[str] = None):
    49          mode = (mode or self.default_mode).lower()
    50          if self.provider == "ollama":
    51              gen = self._ollama_stream(user_text, lang_hint, mode)
    52              return wrap_stream_for_first_token(gen, llm_first_token_latency)
    53          def _one():
    54              yield self.generate(user_text, lang_hint, mode)
    55          return _one()
    56  
    57      def _rule_based(self, user_text: str, lang_hint: str) -> str:
    58          if not (user_text or "").strip():
    59              return "Nu am auzit Ã®ntrebarea. PoÈ›i repeta?"
    60          return f"{'Am Ã®nÈ›eles' if lang_hint.startswith('ro') else 'I heard'}: \"{user_text}\"."
    61  
    62      def _ollama_http(self, user_text: str, lang_hint: str, mode: str = "precise") -> str:
    63          unknown_en = "Thatâ€™s outside my current knowledge, but Iâ€™ll note it for improvement."
    64          unknown_ro = "Interesant, Nu am rÄƒspunsul Ã®ncÄƒ, dar exact Ã®ntrebÄƒri ca asta mÄƒ ajutÄƒ sÄƒ devin mai bun."
    65          unknown = unknown_ro if str(lang_hint).lower().startswith("ro") else unknown_en
    66  
    67          url = f"{self.host.rstrip('/')}/api/generate"
    68  
    69          if mode == "precise":
    70              safety = (
    71                  "IMPORTANT: Answer only with verified facts. "
    72                  f"If you are uncertain or the information may be outdated, reply exactly with: '{unknown}' and suggest checking a reliable source. "
    73                  "Never invent names, dates, or sources. Be concise."
    74              )
    75              temperature = 0.0; top_p = 0.9; top_k = 40
    76          else:
    77              safety = "Be helpful and friendly."
    78              temperature = self.temperature; top_p = 0.95; top_k = 50
    79  
    80          sys = (self.system or "").strip()
    81          preface = f"{sys}\n{safety}".strip()
    82          prompt = f"{preface}\nUser ({lang_hint}): {user_text}\nAssistant:"
    83  
    84          try:
    85              resp = requests.post(url, json={
    86                  "model": self.model,
    87                  "prompt": prompt,
    88                  "stream": False,
    89                  "options": {
    90                      "temperature": temperature,
    91                      "top_p": top_p,
    92                      "top_k": top_k,
    93                      "repeat_penalty": 1.1,
    94                      "num_predict": self.max_tokens
    95                  }
    96              }, timeout=120)
    97              resp.raise_for_status()
    98              data = resp.json()
    99              text = (data.get("response") or "").strip()
   100              if self.strict_facts and not text:
   101                  return unknown
   102              return text or "â€¦"
   103          except Exception as e:
   104              self.log.error(f"Ollama HTTP error: {e}")
   105              return self._rule_based(user_text, lang_hint)
   106  
   107      def _ollama_stream(self, user_text: str, lang_hint: str, mode: str = "precise"):
   108          unknown_en = "Thatâ€™s outside my current knowledge, but Iâ€™ll note it for improvement."
   109          unknown_ro = "Interesant, Nu am rÄƒspunsul Ã®ncÄƒ, dar exact Ã®ntrebÄƒri ca asta mÄƒ ajutÄƒ sÄƒ devin mai bun."
   110          unknown = unknown_ro if str(lang_hint).lower().startswith("ro") else unknown_en
   111  
   112          url = f"{self.host.rstrip('/')}/api/generate"
   113  
   114          if mode == "precise":
   115              safety = (
   116                  "IMPORTANT: Answer only with verified facts. "
   117                  f"If uncertain or outdated, reply exactly with: '{unknown}' "
   118                  "Keep answers concise."
   119              )
   120              temperature = 0.0; top_p = 0.9; top_k = 40
   121          else:
   122              safety = "Be helpful and friendly."
   123              temperature = self.temperature; top_p = 0.95; top_k = 50
   124  
   125          sys = (self.system or "").strip()
   126          prompt = f"{sys}\n{safety}\nUser ({lang_hint}): {user_text}\nAssistant:"
   127  
   128          with requests.post(url, json={
   129              "model": self.model,
   130              "prompt": prompt,
   131              "stream": True,
   132              "options": {
   133                  "temperature": temperature,
   134                  "top_p": top_p,
   135                  "top_k": top_k,
   136                  "repeat_penalty": 1.1,
   137                  "num_predict": self.max_tokens
   138              }
   139          }, stream=True, timeout=120) as resp:
   140              resp.raise_for_status()
   141              for line in resp.iter_lines(decode_unicode=True):
   142                  if not line:
   143                      continue
   144                  try:
   145                      data = json.loads(line)
   146                      tok = (data.get("response") or "")
   147                      if tok:
   148                          yield tok
   149                  except Exception:
   150                      continue
   151  
   152      def _openai_chat(self, user_text: str, lang_hint: str) -> str:
   153          try:
   154              msg = [
   155                  {"role": "system", "content": self.system or "You are concise."},
   156                  {"role": "user", "content": f"[lang={lang_hint}] {user_text}"},
   157              ]
   158              r = self._openai.chat.completions.create(
   159                  model=self.cfg.get("model", "gpt-4o-mini"),
   160                  messages=msg,
   161                  temperature=self.temperature,
   162                  max_tokens=self.max_tokens
   163              )
   164              return (r.choices[0].message.content or "").strip()
   165          except Exception as e:
   166              self.log.error(f"OpenAI error: {e}")
   167              return self._rule_based(user_text, lang_hint)

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/llm/stream_shaper.py =====
     1  # src/llm/stream_shaper.py
     2  from __future__ import annotations
     3  import time
     4  from typing import Iterable, Iterator
     5  
     6  _BOUNDARY = ".!?â€¦:;"
     7  
     8  def _has_boundary(s: str) -> bool:
     9      return any(ch in s for ch in _BOUNDARY)
    10  
    11  def _cut_soft(s: str, soft_max_chars: int) -> tuple[str, str]:
    12      if len(s) <= soft_max_chars:
    13          return s, ""
    14      # taie la ultimul spaÈ›iu Ã®nainte de soft_max
    15      cut = s.rfind(" ", 0, soft_max_chars)
    16      if cut < 40:  # prea aproape de Ã®nceput? taie direct
    17          cut = soft_max_chars
    18      return s[:cut].rstrip(), s[cut:].lstrip()
    19  
    20  def shape_stream(
    21      token_iter: Iterable[str],
    22      prebuffer_chars: int = 120,   # aÈ™teaptÄƒ puÈ›in Ã®nainte de primul sunet => start mai lin
    23      min_chunk_chars: int = 60,    # nu livra bucÄƒÈ›i prea mici
    24      soft_max_chars: int = 140,    # forÈ›eazÄƒ flush dacÄƒ devine prea lung fÄƒrÄƒ punctuaÈ›ie
    25      max_idle_ms: int = 250,       # dacÄƒ nu vin tokeni o fracÈ›iune de secundÄƒ, flusheazÄƒ ce ai
    26  ) -> Iterator[str]:
    27      """
    28      StrÃ¢nge tokenii Ã®n fraze stabile:
    29        - porneÈ™te vorbirea doar dupÄƒ ~prebuffer_chars
    30        - apoi livreazÄƒ cÃ¢nd gÄƒseÈ™te punctuaÈ›ie sau depÄƒÈ™eÈ™te soft_max_chars
    31        - dacÄƒ nu mai vin tokeni o clipÄƒ, flusheazÄƒ ce ai (max_idle_ms)
    32      """
    33      buf = []
    34      buf_chars = 0
    35  
    36      # 1) prebuffer iniÈ›ial â€” evitÄƒ startul Ã®n mijloc de propoziÈ›ie
    37      t_last = time.monotonic()
    38      for tok in token_iter:
    39          buf.append(tok)
    40          buf_chars += len(tok)
    41          t_last = time.monotonic()
    42          if buf_chars >= prebuffer_chars:
    43              break
    44  
    45      if buf_chars:
    46          yield "".join(buf)
    47          buf = []
    48          buf_chars = 0
    49  
    50      # 2) rulare normalÄƒ â€” preferÄƒ propoziÈ›ii complete, dar fÄƒrÄƒ pauze lungi
    51      carry = ""
    52      t_last = time.monotonic()
    53      for tok in token_iter:
    54          carry += tok
    55          now = time.monotonic()
    56          # avem propoziÈ›ie completÄƒ?
    57          if _has_boundary(carry) and len(carry) >= min_chunk_chars:
    58              out = carry
    59              carry = ""
    60              yield out
    61              t_last = now
    62              continue
    63  
    64          # prea lung fÄƒrÄƒ punctuaÈ›ie? taie blÃ¢nd
    65          if len(carry) >= soft_max_chars:
    66              head, tail = _cut_soft(carry, soft_max_chars)
    67              if head:
    68                  yield head
    69                  t_last = now
    70              carry = tail
    71              continue
    72  
    73          # idle flush (dacÄƒ nu mai vin tokeni)
    74          if (now - t_last) * 1000 >= max_idle_ms and carry:
    75              yield carry
    76              carry = ""
    77              t_last = now
    78  
    79      # 3) finalizeazÄƒ restul
    80      if carry.strip():
    81          yield carry

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/telemetry/metrics.py =====
     1  from prometheus_client import Counter, Histogram, make_wsgi_app
     2  from wsgiref.simple_server import make_server, WSGIServer
     3  from socketserver import ThreadingMixIn
     4  from contextlib import contextmanager
     5  import threading, os, time, html
     6  
     7  # ---- METRICS DEFINITIONS ----
     8  asr_latency = Histogram("asr_latency_seconds", "ASR transcription latency (seconds)")
     9  llm_latency = Histogram("llm_latency_seconds", "LLM request latency until completion (seconds)")
    10  llm_first_token_latency = Histogram("llm_first_token_latency_seconds", "Latency from LLM request to first token (seconds)")
    11  tts_latency = Histogram("tts_latency_seconds", "TTS blocking speak latency (seconds)")
    12  round_trip = Histogram("round_trip_seconds", "Latency from end of user recording to issuing TTS (seconds)")
    13  
    14  wake_triggers = Counter("wake_triggers_total", "Wake phrases successfully detected")
    15  sessions_started = Counter("sessions_started_total", "Conversation sessions started")
    16  sessions_ended = Counter("sessions_ended_total", "Conversation sessions ended")
    17  interactions = Counter("interactions_total", "Turns inside active sessions")
    18  unknown_answer = Counter("unknown_answer_total", "LLM replied unknown/uncertain")
    19  errors_total = Counter("errors_total", "Unhandled errors")
    20  tts_speak_calls = Counter("tts_speak_calls_total", "Number of TTS speak calls")
    21  
    22  # ---- HELPERS ----
    23  def _hist_sum_count(hist: Histogram):
    24      """ReturneazÄƒ (sum, count) pentru un histogram fÄƒrÄƒ etichete."""
    25      s = c = 0.0
    26      for metric in hist.collect():
    27          for sample in metric.samples:
    28              # sample are cÃ¢mpuri: name, labels, value, timestamp, exemplar
    29              if sample.labels:  # ignorÄƒ variantele etichetate
    30                  continue
    31              if sample.name.endswith("_sum"):
    32                  s = float(sample.value)
    33              elif sample.name.endswith("_count"):
    34                  c = float(sample.value)
    35      return s, c
    36  
    37  def _counter_val(cnt: Counter):
    38      val = 0.0
    39      for metric in cnt.collect():
    40          for sample in metric.samples:
    41              if sample.labels:
    42                  continue
    43              if sample.name.endswith("_total"):
    44                  val = float(sample.value)
    45      return val
    46  
    47  def _fmt_ms(avg_s, count):
    48      if count <= 0:
    49          return "â€”"
    50      return f"{avg_s*1000:.0f} ms (n={int(count)})"
    51  
    52  def _render_vitals_html():
    53      hs = [
    54          ("Round-trip", round_trip),
    55          ("ASR latency", asr_latency),
    56          ("LLM first token", llm_first_token_latency),
    57          ("LLM total", llm_latency),
    58          ("TTS latency", tts_latency),
    59      ]
    60      cs = [
    61          ("Wake triggers", wake_triggers),
    62          ("Sessions started", sessions_started),
    63          ("Sessions ended", sessions_ended),
    64          ("Turns (interactions)", interactions),
    65          ("TTS speak calls", tts_speak_calls),
    66          ("\"Unknown\" replies", unknown_answer),
    67          ("Errors", errors_total),
    68      ]
    69  
    70      rows_lat = []
    71      for label, h in hs:
    72          s, c = _hist_sum_count(h)
    73          avg = (s / c) if c else 0.0
    74          rows_lat.append((label, _fmt_ms(avg, c)))
    75  
    76      rows_cnt = [(label, f"{int(_counter_val(cn))}") for label, cn in cs]
    77  
    78      css = """
    79      <style>
    80        body { font: 14px/1.4 -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen, Ubuntu, Cantarell, system-ui, sans-serif; margin: 24px; }
    81        h1 { margin: 0 0 8px; font-size: 20px; }
    82        .small { color:#666; margin-bottom:16px }
    83        table { border-collapse: collapse; margin: 12px 0 24px; min-width: 420px; }
    84        th, td { padding: 8px 12px; border-bottom: 1px solid #eee; text-align: left; }
    85        th { background: #fafafa; }
    86        .grid { display:flex; gap:32px; flex-wrap: wrap; }
    87        .card { padding:16px; border:1px solid #eee; border-radius:12px; box-shadow:0 1px 2px rgba(0,0,0,.04); }
    88        a { color:#3366cc; text-decoration:none; }
    89        a:hover { text-decoration:underline; }
    90      </style>
    91      """
    92      lat_rows_html = "\n".join(f"<tr><td>{html.escape(k)}</td><td><b>{html.escape(v)}</b></td></tr>" for k,v in rows_lat)
    93      cnt_rows_html = "\n".join(f"<tr><td>{html.escape(k)}</td><td><b>{html.escape(v)}</b></td></tr>" for k,v in rows_cnt)
    94  
    95      html_doc = f"""<!doctype html>
    96  <html><head><meta charset="utf-8"><title>Robot Vitals</title>{css}</head>
    97  <body>
    98    <h1>Robot Vitals</h1>
    99    <div class="small">Only the important stuff. Full Prometheus at <a href="/metrics">/metrics</a>.</div>
   100    <div class="grid">
   101      <div class="card">
   102        <h3>Latency (avg)</h3>
   103        <table><thead><tr><th>Metric</th><th>Value</th></tr></thead>
   104        <tbody>{lat_rows_html}</tbody></table>
   105        <div class="small">Tip: Round-trip = end of user speech â†’ TTS start.</div>
   106      </div>
   107      <div class="card">
   108        <h3>Counters</h3>
   109        <table><thead><tr><th>Metric</th><th>Value</th></tr></thead>
   110        <tbody>{cnt_rows_html}</tbody></table>
   111      </div>
   112    </div>
   113  </body></html>"""
   114      return html_doc.encode("utf-8")
   115  
   116  class ThreadingWSGIServer(ThreadingMixIn, WSGIServer):
   117      daemon_threads = True
   118  
   119  def _router_app(environ, start_response):
   120      path = environ.get("PATH_INFO") or "/"
   121      if path == "/metrics":
   122          return make_wsgi_app()(environ, start_response)
   123      if path == "/" or path == "/vitals":
   124          start_response("200 OK", [("Content-Type", "text/html; charset=utf-8")])
   125          return [_render_vitals_html()]
   126      start_response("404 Not Found", [("Content-Type", "text/plain; charset=utf-8")])
   127      return [b"Not Found"]
   128  
   129  def boot_metrics():
   130      addr = os.getenv("METRICS_ADDR", "127.0.0.1")
   131      port = int(os.getenv("METRICS_PORT", "9108"))
   132      httpd = make_server(addr, port, _router_app, server_class=ThreadingWSGIServer)
   133      th = threading.Thread(target=httpd.serve_forever, daemon=True)
   134      th.start()
   135  
   136      # Self-test opÈ›ional ca sÄƒ nu vezi 0 la Ã®nceput
   137      if os.getenv("METRICS_SELFTEST", "0") == "1":
   138          wake_triggers.inc()
   139          sessions_started.inc()
   140          interactions.inc()
   141          tts_speak_calls.inc()
   142          with observe_hist(asr_latency): time.sleep(0.12)
   143          with observe_hist(round_trip): time.sleep(0.22)
   144          with observe_hist(tts_latency): time.sleep(0.05)
   145          sessions_ended.inc()
   146      return addr, port
   147  
   148  @contextmanager
   149  def observe_hist(hist: Histogram):
   150      start = time.perf_counter()
   151      try:
   152          yield
   153      finally:
   154          hist.observe(time.perf_counter() - start)
   155  
   156  def wrap_stream_for_first_token(generator, hist: Histogram):
   157      first = {"done": False}
   158      start = time.perf_counter()
   159      def gen():
   160          for tok in generator:
   161              if not first["done"]:
   162                  first["done"] = True
   163                  hist.observe(time.perf_counter() - start)
   164              yield tok
   165      return gen()

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/tts/__init__.py =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/tts/engine.py =====
     1  # src/tts/engine.py
     2  from __future__ import annotations
     3  from typing import Dict, Optional, Iterable, Callable
     4  import threading, re, os, shutil, subprocess, tempfile, time, queue
     5  import soundfile as sf
     6  import sounddevice as sd
     7  
     8  from src.telemetry.metrics import tts_speak_calls
     9  
    10  _SENT_SPLIT = re.compile(r'([.!?â€¦:;]+)\s+')
    11  
    12  # -------------------- PYTTSX3 BACKEND --------------------
    13  class _Pyttsx3TTS:
    14      def __init__(self, cfg: Dict, logger):
    15          import pyttsx3
    16          self.log = logger
    17          self.eng = pyttsx3.init()
    18          self.rate = int(cfg.get("rate", 170))
    19          self.volume = float(cfg.get("volume", 1.0))
    20          self.voice_ro_hint = cfg.get("voice_ro_hint", "ro")
    21          self.voice_en_hint = cfg.get("voice_en_hint", "en")
    22          self.eng.setProperty("rate", self.rate)
    23          self.eng.setProperty("volume", self.volume)
    24          self._voices = self.eng.getProperty("voices")
    25  
    26          self._lock = threading.Lock()
    27          self._stop = threading.Event()
    28          self._speaking = threading.Event()
    29          self._speak_th: Optional[threading.Thread] = None
    30  
    31      def _pick_voice(self, lang: str) -> Optional[str]:
    32          target = (self.voice_ro_hint if lang.startswith("ro") else self.voice_en_hint or "").lower()
    33          for v in self._voices:
    34              name = (getattr(v, "name", "") or "").lower()
    35              _id  = (getattr(v, "id", "") or "").lower()
    36              if target and (target in name or target in _id):
    37                  return v.id
    38          return self._voices[0].id if self._voices else None
    39  
    40      def is_speaking(self) -> bool:
    41          return self._speaking.is_set()
    42  
    43      def say(self, text: str, lang: str = "en"):
    44          vid = self._pick_voice(lang)
    45          if vid: self.eng.setProperty("voice", vid)
    46          else:   self.log.warning("âš ï¸ Nicio voce potrivitÄƒ (pyttsx3) â€“ folosesc default.")
    47          tts_speak_calls.inc()
    48          self._speaking.set()
    49          try:
    50              self.eng.say(text)
    51              self.eng.runAndWait()
    52          finally:
    53              self._speaking.clear()
    54  
    55      def say_async_stream(
    56          self,
    57          token_iter: Iterable[str],
    58          lang: str = "en",
    59          on_first_speak: Optional[Callable[[], None]] = None,
    60          min_chunk_chars: int = 80,
    61          on_done: Optional[Callable[[], None]] = None,
    62      ):
    63          def worker():
    64              first_spoken = False
    65              buf = ""
    66              vid = self._pick_voice(lang)
    67              if vid: self.eng.setProperty("voice", vid)
    68              tts_speak_calls.inc()
    69              self._speaking.set()
    70              try:
    71                  for tok in token_iter:
    72                      if self._stop.is_set():
    73                          break
    74                      buf += tok
    75  
    76                      parts = _SENT_SPLIT.split(buf)
    77                      out = []
    78                      if len(parts) >= 2:
    79                          for i in range(0, len(parts)-1, 2):
    80                              frag, punct = parts[i], parts[i+1]
    81                              s = (frag + punct).strip()
    82                              if s: out.append(s)
    83                          buf = parts[-1] if (len(parts) % 2 == 1) else ""
    84  
    85                      if not out and len(buf) >= min_chunk_chars:
    86                          last_space = buf.rfind(" ")
    87                          if last_space > 20:
    88                              out.append(buf[:last_space].strip())
    89                              buf = buf[last_space+1:]
    90  
    91                      for sentence in out:
    92                          if self._stop.is_set():
    93                              break
    94                          if on_first_speak and not first_spoken:
    95                              first_spoken = True
    96                              try: on_first_speak()
    97                              except Exception: pass
    98                          self.eng.say(sentence)
    99                          self.eng.runAndWait()
   100  
   101                  if not self._stop.is_set() and buf.strip():
   102                      if on_first_speak and not first_spoken:
   103                          first_spoken = True
   104                          try: on_first_speak()
   105                          except Exception: pass
   106                      self.eng.say(buf.strip())
   107                      self.eng.runAndWait()
   108              except Exception as e:
   109                  self.log.error(f"TTS stream error (pyttsx3): {e}")
   110              finally:
   111                  self._speaking.clear()
   112                  if on_done:
   113                      try: on_done()
   114                      except Exception: pass
   115  
   116          self.stop()
   117          self._stop.clear()
   118          self._speak_th = threading.Thread(target=worker, daemon=True)
   119          self._speak_th.start()
   120          return self._speaking
   121  
   122      def stop(self):
   123          with self._lock:
   124              self._stop.set()
   125              try: self.eng.stop()
   126              except Exception: pass
   127          self._speaking.clear()
   128  
   129  # -------------------- PIPER (CLI) BACKEND â€” DOUBLE BUFFER --------------------
   130  class _PiperCmdTTS:
   131      """
   132      Piper backend cu dublu-buffer:
   133        - Producer-ul segmenteazÄƒ stream-ul LLM Ã®n propoziÈ›ii/bucÄƒÈ›i, sintetizeazÄƒ WAV-urile urmÄƒtoare
   134          È™i le pune Ã®ntr-o coadÄƒ cu max 2 elemente (A/B).
   135        - Consumer-ul redÄƒ Ã®n timp real fiÈ™ierul curent, Ã®n timp ce urmÄƒtorul e deja prefÄƒcut.
   136        - Loguri:
   137            ğŸ§   LLMâ†’TTS chunk: <text>   (Ã®nainte de sintezÄƒ)
   138            ğŸ”Š  TTS play start: <N>     (cÃ¢nd Ã®ncepe redarea)
   139      """
   140      def __init__(self, cfg: Dict, logger):
   141          self.log = logger
   142          self.cfg = cfg or {}
   143          self.p = self.cfg.get("piper") or {}
   144          self.exe = self.p.get("exe") or shutil.which("piper")
   145          self.model_ro = self.p.get("model_ro")
   146          self.config_ro = self.p.get("config_ro")
   147          self.model_en = self.p.get("model_en")
   148          self.config_en = self.p.get("config_en")
   149          self.speaker_id = self.p.get("speaker_id", None)
   150          self.length_scale = float(self.p.get("length_scale", 1.0))
   151          self.noise_scale = float(self.p.get("noise_scale", 0.667))
   152          self.noise_w = float(self.p.get("noise_w", 0.8))
   153          self.sentence_silence_ms = int(self.p.get("sentence_silence_ms", 80))
   154  
   155          # Control
   156          self._lock = threading.Lock()
   157          self._stop = threading.Event()
   158          self._speaking = threading.Event()
   159  
   160          # Double buffer queue (A/B)
   161          self._q: "queue.Queue[Optional[str]]" = queue.Queue(maxsize=2)
   162          self._producer_th: Optional[threading.Thread] = None
   163          self._consumer_th: Optional[threading.Thread] = None
   164          self._coord_th: Optional[threading.Thread] = None
   165          self._play_proc: Optional[subprocess.Popen] = None
   166          self._staged_paths: set[str] = set()
   167  
   168          if not self.exe or not os.path.exists(self.exe):
   169              raise RuntimeError("Piper executable not found. Set tts.piper.exe or install piper-tts.")
   170  
   171      def is_speaking(self) -> bool:
   172          return self._speaking.is_set()
   173  
   174      def _pick_model(self, lang: str):
   175          if lang.startswith("ro"):
   176              return self.model_ro, self.config_ro
   177          return self.model_en, self.config_en
   178  
   179      def _synth_to_wav(self, text: str, lang: str) -> str:
   180          model, cfg = self._pick_model(lang)
   181          if not (model and os.path.exists(model)):
   182              raise RuntimeError("Piper model not set/found for selected language.")
   183          fd, path = tempfile.mkstemp(prefix=f"piper_{lang}_", suffix=".wav")
   184          os.close(fd)
   185  
   186          cmd = [self.exe, "--model", model, "--output_file", path]
   187          if cfg and os.path.exists(cfg):
   188              cmd += ["--config", cfg]
   189          if self.speaker_id is not None:
   190              cmd += ["--speaker", str(self.speaker_id)]
   191          # length/noise se pot lÄƒsa Ã®n .json dacÄƒ binarul nu suportÄƒ flag-urile
   192  
   193          try:
   194              subprocess.run(cmd, input=text.encode("utf-8"), check=True)
   195              return path
   196          except subprocess.CalledProcessError as e:
   197              self.log.error(f"Piper synth failed: {e}")
   198              raise
   199  
   200      def _play_wav(self, wav_path: str):
   201          # 1) paplay (PulseAudio/PipeWire)
   202          player = shutil.which("paplay")
   203          if player:
   204              self._play_proc = subprocess.Popen([player, wav_path])
   205              while self._play_proc.poll() is None:
   206                  if self._stop.is_set():
   207                      self._play_proc.terminate()
   208                      break
   209                  time.sleep(0.02)
   210              return
   211  
   212          # 2) aplay (ALSA)
   213          player = shutil.which("aplay")
   214          if player:
   215              self._play_proc = subprocess.Popen([player, "-q", wav_path])
   216              while self._play_proc.poll() is None:
   217                  if self._stop.is_set():
   218                      self._play_proc.terminate()
   219                      break
   220                  time.sleep(0.02)
   221              return
   222  
   223          # 3) fallback Python (sounddevice)
   224          try:
   225              data, sr = sf.read(wav_path, dtype="float32")
   226              sd.play(data, sr)
   227              while sd.get_stream() and sd.get_stream().active:
   228                  if self._stop.is_set():
   229                      sd.stop()
   230                      break
   231                  time.sleep(0.02)
   232              sd.wait()
   233          except Exception as e:
   234              self.log.error(f"Audio playback error: {e}")
   235  
   236      # ---------- FIX: producer robust + sentinel garantat ----------
   237      def _producer(self, token_iter: Iterable[str], lang: str, min_chunk_chars: int):
   238          try:
   239              buf = ""
   240              for tok in token_iter:
   241                  if self._stop.is_set():
   242                      break
   243                  buf += tok
   244  
   245                  parts = _SENT_SPLIT.split(buf)
   246                  out = []
   247                  if len(parts) >= 2:
   248                      for i in range(0, len(parts) - 1, 2):
   249                          frag, punct = parts[i], parts[i + 1]
   250                          s = (frag + punct).strip()
   251                          if s:
   252                              out.append(s)
   253                      buf = parts[-1] if (len(parts) % 2 == 1) else ""
   254  
   255                  if not out and len(buf) >= min_chunk_chars:
   256                      last_space = buf.rfind(" ")
   257                      if last_space > 20:
   258                          out.append(buf[:last_space].strip())
   259                          buf = buf[last_space + 1:]
   260  
   261                  for s in out:
   262                      if self._stop.is_set():
   263                          break
   264                      self.log.info(f"ğŸ§  LLMâ†’TTS chunk [{len(s)}c]: {s}")
   265                      wav = self._synth_to_wav(s, lang)
   266                      self._staged_paths.add(wav)
   267                      while not self._stop.is_set():
   268                          try:
   269                              self._q.put(wav, timeout=0.1)
   270                              break
   271                          except queue.Full:
   272                              continue
   273  
   274              tail = buf.strip()
   275              if (not self._stop.is_set()) and tail:
   276                  self.log.info(f"ğŸ§  LLMâ†’TTS chunk [{len(tail)}c]: {tail}")
   277                  wav = self._synth_to_wav(tail, lang)
   278                  self._staged_paths.add(wav)
   279                  while not self._stop.is_set():
   280                      try:
   281                          self._q.put(wav, timeout=0.1)
   282                          break
   283                      except queue.Full:
   284                          continue
   285          except Exception as e:
   286              self.log.error(f"Piper producer error: {e}")
   287          finally:
   288              # Sentinel garantat: livreazÄƒ None chiar dacÄƒ coada e plinÄƒ
   289              while not self._stop.is_set():
   290                  try:
   291                      self._q.put(None, timeout=0.1)
   292                      break
   293                  except queue.Full:
   294                      continue
   295  
   296      def _consumer(self, on_first_speak: Optional[Callable[[], None]]):
   297          first = True
   298          n = 0
   299          try:
   300              while not self._stop.is_set():
   301                  try:
   302                      item = self._q.get(timeout=0.1)
   303                  except queue.Empty:
   304                      continue
   305                  if item is None:
   306                      break
   307                  wav = item
   308                  n += 1
   309                  if on_first_speak and first:
   310                      first = False
   311                      try:
   312                          on_first_speak()
   313                      except Exception:
   314                          pass
   315                  self.log.info(f"ğŸ”Š TTS play start (chunk {n})")
   316                  try:
   317                      self._play_wav(wav)
   318                  finally:
   319                      try:
   320                          if wav in self._staged_paths:
   321                              os.remove(wav)
   322                              self._staged_paths.discard(wav)
   323                      except Exception:
   324                          pass
   325  
   326                  # mic gap Ã®ntre bucÄƒÈ›i, dacÄƒ e configurat
   327                  if self.sentence_silence_ms > 0 and not self._stop.is_set():
   328                      t0 = time.time()
   329                      while (time.time() - t0) * 1000 < self.sentence_silence_ms and not self._stop.is_set():
   330                          time.sleep(0.003)
   331          except Exception as e:
   332              self.log.error(f"Piper consumer error: {e}")
   333  
   334      def say(self, text: str, lang: str = "en"):
   335          """SintezÄƒ blocking pe propoziÈ›ii (fÄƒrÄƒ stream din LLM)."""
   336          tts_speak_calls.inc()
   337          self._speaking.set()
   338          try:
   339              parts = _SENT_SPLIT.split(text)
   340              sentences = []
   341              if len(parts) >= 2:
   342                  for i in range(0, len(parts)-1, 2):
   343                      frag, punct = parts[i], parts[i+1]
   344                      s = (frag + punct).strip()
   345                      if s: sentences.append(s)
   346                  tail = parts[-1].strip() if (len(parts) % 2 == 1) else ""
   347                  if tail: sentences.append(tail)
   348              else:
   349                  if text.strip():
   350                      sentences = [text.strip()]
   351  
   352              for s in sentences:
   353                  if self._stop.is_set(): break
   354                  self.log.info(f"ğŸ§  LLMâ†’TTS chunk [{len(s)}c]: {s}")
   355                  wav = self._synth_to_wav(s, lang)
   356                  try:
   357                      self.log.info("ğŸ”Š TTS play start (blocking)")
   358                      self._play_wav(wav)
   359                  finally:
   360                      try: os.remove(wav)
   361                      except Exception: pass
   362                  if self.sentence_silence_ms > 0:
   363                      t0 = time.time()
   364                      while (time.time() - t0) * 1000 < self.sentence_silence_ms and not self._stop.is_set():
   365                          time.sleep(0.003)
   366          finally:
   367              self._speaking.clear()
   368  
   369      # ---------- FIX: coordonatorul asigurÄƒ oprirea corectÄƒ + revenire Ã®n listen ----------
   370      def say_async_stream(
   371          self,
   372          token_iter: Iterable[str],
   373          lang: str = "en",
   374          on_first_speak: Optional[Callable[[], None]] = None,
   375          min_chunk_chars: int = 80,
   376          on_done: Optional[Callable[[], None]] = None,
   377      ):
   378          def coordinator():
   379              try:
   380                  self._speaking.set()
   381                  tts_speak_calls.inc()
   382  
   383                  # PorneÈ™te producer + consumer
   384                  self._producer_th = threading.Thread(
   385                      target=self._producer,
   386                      args=(token_iter, lang, int(min_chunk_chars)),
   387                      daemon=True,
   388                  )
   389                  self._consumer_th = threading.Thread(
   390                      target=self._consumer,
   391                      args=(on_first_speak,),
   392                      daemon=True,
   393                  )
   394                  self._producer_th.start()
   395                  self._consumer_th.start()
   396  
   397                  # AÈ™teaptÄƒ producer-ul, apoi injecteazÄƒ sentinel dacÄƒ mai e nevoie
   398                  self._producer_th.join()
   399                  while self._consumer_th.is_alive() and not self._stop.is_set():
   400                      try:
   401                          self._q.put(None, timeout=0.1)
   402                          break
   403                      except queue.Full:
   404                          time.sleep(0.05)
   405                          continue
   406  
   407                  self._consumer_th.join()
   408              finally:
   409                  self._speaking.clear()
   410                  if on_done:
   411                      try: on_done()
   412                      except Exception: pass
   413  
   414          # reset pipeline
   415          self.stop()
   416          self._stop.clear()
   417          self._q = queue.Queue(maxsize=2)
   418  
   419          self._coord_th = threading.Thread(target=coordinator, daemon=True)
   420          self._coord_th.start()
   421          return self._speaking
   422  
   423      def stop(self):
   424          with self._lock:
   425              self._stop.set()
   426              try:
   427                  if self._play_proc and self._play_proc.poll() is None:
   428                      self._play_proc.terminate()
   429              except Exception:
   430                  pass
   431          # È™terge WAV-urile neconsumate
   432          for p in list(self._staged_paths):
   433              try:
   434                  os.remove(p)
   435              except Exception:
   436                  pass
   437              self._staged_paths.discard(p)
   438          self._speaking.clear()
   439  
   440  
   441  # -------------------- FACADE --------------------
   442  class TTSLocal:
   443      """
   444      Alege backend-ul Ã®n funcÈ›ie de configs/tts.yaml:
   445        - backend: piper  -> _PiperCmdTTS (cu dublu-buffer)
   446        - altfel         -> _Pyttsx3TTS (fallback)
   447      """
   448      def __init__(self, cfg: Dict, logger):
   449          self.log = logger
   450          backend = (cfg.get("backend") or "pyttsx3").lower()
   451          try:
   452              if backend == "piper":
   453                  self.impl = _PiperCmdTTS(cfg, logger)
   454                  self.log.info("TTS backend: Piper (double-buffer)")
   455              else:
   456                  raise RuntimeError("force pyttsx3")
   457          except Exception as e:
   458              self.log.warning(f"Piper indisponibil ({e}). Revin pe pyttsx3.")
   459              self.impl = _Pyttsx3TTS(cfg, logger)
   460              self.log.info("TTS backend: pyttsx3")
   461  
   462      def is_speaking(self) -> bool:
   463          return self.impl.is_speaking()
   464  
   465      def say(self, text: str, lang: str = "en"):
   466          return self.impl.say(text, lang)
   467  
   468      def say_async_stream(
   469          self,
   470          token_iter: Iterable[str],
   471          lang: str = "en",
   472          on_first_speak: Optional[Callable[[], None]] = None,
   473          min_chunk_chars: int = 80,
   474          on_done: Optional[Callable[[], None]] = None,
   475      ):
   476          return self.impl.say_async_stream(token_iter, lang, on_first_speak, min_chunk_chars, on_done)
   477  
   478      def stop(self):
   479          return self.impl.stop()

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/tts/piper_backend.py =====
     1  # src/tts/piper_backend.py
     2  from __future__ import annotations
     3  from typing import Dict, Optional, Iterable, Callable
     4  import os, re, threading, subprocess, tempfile, time
     5  import sounddevice as sd
     6  import soundfile as sf
     7  
     8  _SENT_SPLIT = re.compile(r'([.!?â€¦:;]+)\s+')
     9  
    10  class PiperTTS:
    11      """
    12      Backend TTS pentru Piper (foloseÈ™te binarul `piper` prin subprocess).
    13      - GenereazÄƒ WAV per frazÄƒ (sau bucÄƒÈ›i) È™i redÄƒ cu sounddevice.
    14      - DacÄƒ lipsesc binarul sau modelele -> aruncÄƒ excepÈ›ie (app va face fallback la pyttsx3).
    15      """
    16      def __init__(self, cfg: Dict, logger):
    17          self.log = logger
    18          self.cfg = cfg or {}
    19          self.eng = None  # doar pentru simetrie cu pyttsx3
    20  
    21          self.exe = (self.cfg.get("piper", {}).get("exe") or "").strip()
    22          self.model_ro = (self.cfg.get("piper", {}).get("model_ro") or "").strip()
    23          self.config_ro = (self.cfg.get("piper", {}).get("config_ro") or "").strip()
    24          self.model_en = (self.cfg.get("piper", {}).get("model_en") or "").strip()
    25          self.config_en = (self.cfg.get("piper", {}).get("config_en") or "").strip()
    26  
    27          self.speaker_id = self.cfg.get("piper", {}).get("speaker_id", None)
    28          self.length_scale = float(self.cfg.get("piper", {}).get("length_scale", 1.0))
    29          self.noise_scale  = float(self.cfg.get("piper", {}).get("noise_scale", 0.667))
    30          self.noise_w      = float(self.cfg.get("piper", {}).get("noise_w", 0.8))
    31          self.sil_ms       = int(self.cfg.get("piper", {}).get("sentence_silence_ms", 80))
    32  
    33          # controale runtime
    34          self._lock = threading.Lock()
    35          self._stop = threading.Event()
    36          self._speaking = threading.Event()
    37          self._speak_th: Optional[threading.Thread] = None
    38  
    39          # sanity checks
    40          if not (self.exe and os.path.exists(self.exe)):
    41              raise RuntimeError("Piper binar lipsÄƒ sau cale greÈ™itÄƒ. VerificÄƒ tts.piper.exe")
    42          if not (os.path.exists(self.model_ro) and os.path.exists(self.model_en)):
    43              raise RuntimeError("Modelele Piper lipsÄƒ sau cÄƒi greÈ™ite (model_ro/model_en).")
    44  
    45          self.log.info(f"Piper TTS ready (exe={self.exe})")
    46  
    47      def is_speaking(self) -> bool:
    48          return self._speaking.is_set()
    49  
    50      # -------------- synth helpers --------------
    51      def _model_for_lang(self, lang: str):
    52          if str(lang).lower().startswith("ro"):
    53              return self.model_ro, (self.config_ro if self.config_ro else None)
    54          return self.model_en, (self.config_en if self.config_en else None)
    55  
    56      def _synth_to_wav(self, text: str, lang: str) -> str:
    57          """RuleazÄƒ `piper` pe text È™i returneazÄƒ path-ul unui WAV temporar."""
    58          model, cfg = self._model_for_lang(lang)
    59          out_wav = tempfile.NamedTemporaryFile(prefix="piper_", suffix=".wav", delete=False)
    60          out_wav_path = out_wav.name
    61          out_wav.close()
    62  
    63          # Construim comanda Piper (folosim opÈ›iuni uzuale; cfg/speaker sunt opÈ›ionale)
    64          cmd = [self.exe, "--model", model, "--output_file", out_wav_path,
    65                 "--length_scale", str(self.length_scale),
    66                 "--noise_scale", str(self.noise_scale),
    67                 "--noise_w", str(self.noise_w),
    68          ]
    69          if cfg and os.path.exists(cfg):
    70              cmd += ["--config", cfg]
    71          if self.speaker_id is not None:
    72              cmd += ["--speaker", str(self.speaker_id)]
    73  
    74          try:
    75              # piper citeÈ™te textul de la stdin (utf-8)
    76              proc = subprocess.run(
    77                  cmd, input=text.encode("utf-8"),
    78                  stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True
    79              )
    80          except subprocess.CalledProcessError as e:
    81              stderr = (e.stderr or b"").decode("utf-8", "ignore")
    82              self.log.error(f"Piper synth error: {stderr}")
    83              raise
    84          return out_wav_path
    85  
    86      def _play_wav_blocking(self, wav_path: str):
    87          """RedÄƒ WAV blocking. RespectÄƒ self._stop pentru barge/stop imediat."""
    88          try:
    89              data, sr = sf.read(wav_path, dtype="int16", always_2d=False)
    90              # data poate fi (n,) mono sau (n, ch). Piper e mono.
    91              if data.ndim == 2:
    92                  # mix la mono dacÄƒ e cazul
    93                  data = data.mean(axis=1).astype("int16")
    94          except Exception as e:
    95              self.log.error(f"Nu pot citi WAV generat de Piper: {e}")
    96              return
    97  
    98          # redare frame-by-frame ca sÄƒ putem opri repede
    99          block = int(sr * 0.05)  # 50ms
   100          try:
   101              with sd.OutputStream(samplerate=sr, channels=1, dtype="int16") as stream:
   102                  i = 0
   103                  while i < len(data) and not self._stop.is_set():
   104                      chunk = data[i:i+block]
   105                      stream.write(chunk)
   106                      i += block
   107          except Exception as e:
   108              self.log.error(f"Eroare la redare audio: {e}")
   109  
   110      def _sleep_ms(self, ms: int):
   111          t0 = time.time()
   112          while (time.time() - t0) * 1000 < ms and not self._stop.is_set():
   113              time.sleep(0.005)
   114  
   115      # -------------- public API (similar cu TTSLocal) --------------
   116      def say(self, text: str, lang: str = "en"):
   117          """SintezÄƒ blocking, pe propoziÈ›ii."""
   118          self._stop.clear()
   119          self._speaking.set()
   120          try:
   121              parts = _SENT_SPLIT.split(text)
   122              sentences = []
   123              if len(parts) >= 2:
   124                  for i in range(0, len(parts)-1, 2):
   125                      frag, punct = parts[i], parts[i+1]
   126                      s = (frag + punct).strip()
   127                      if s: sentences.append(s)
   128                  tail = parts[-1].strip() if (len(parts) % 2 == 1) else ""
   129                  if tail: sentences.append(tail)
   130              else:
   131                  if text.strip():
   132                      sentences = [text.strip()]
   133  
   134              for s in sentences:
   135                  if self._stop.is_set(): break
   136                  wav = self._synth_to_wav(s, lang)
   137                  try:
   138                      self._play_wav_blocking(wav)
   139                  finally:
   140                      try: os.remove(wav)
   141                      except: pass
   142                  if self.sil_ms > 0:
   143                      self._sleep_ms(self.sil_ms)
   144          finally:
   145              self._speaking.clear()
   146  
   147      def say_async(self, text: str, lang: str = "en"):
   148          def worker():
   149              try:
   150                  self.say(text, lang=lang)
   151              except Exception as e:
   152                  self.log.error(f"Piper async error: {e}")
   153              finally:
   154                  self._speaking.clear()
   155          self.stop()
   156          self._stop.clear()
   157          self._speaking.set()
   158          self._speak_th = threading.Thread(target=worker, daemon=True)
   159          self._speak_th.start()
   160  
   161      def say_async_stream(
   162          self,
   163          token_iter: Iterable[str],
   164          lang: str = "en",
   165          on_first_speak: Optional[Callable[[], None]] = None,
   166          min_chunk_chars: int = 80,
   167          on_done: Optional[Callable[[], None]] = None,
   168      ):
   169          """
   170          Stream: acumuleazÄƒ tokeni pÃ¢nÄƒ la final de propoziÈ›ie sau buffer >= min_chunk_chars,
   171          sintetizeazÄƒ È™i redÄƒ imediat (cu pauze scurte Ã®ntre bucÄƒÈ›i).
   172          """
   173          def worker():
   174              first_spoken = False
   175              buf = ""
   176              self._speaking.set()
   177              try:
   178                  for tok in token_iter:
   179                      if self._stop.is_set(): break
   180                      buf += tok
   181  
   182                      # taie la propoziÈ›ii complete
   183                      parts = _SENT_SPLIT.split(buf)
   184                      out = []
   185                      if len(parts) >= 2:
   186                          for i in range(0, len(parts)-1, 2):
   187                              frag, punct = parts[i], parts[i+1]
   188                              s = (frag + punct).strip()
   189                              if s:
   190                                  out.append(s)
   191                          buf = parts[-1] if (len(parts) % 2 == 1) else ""
   192  
   193                      # sau dacÄƒ e foarte lung È™i n-avem punctuaÈ›ie, taie la cel mai apropiat spaÈ›iu
   194                      if not out and len(buf) >= min_chunk_chars:
   195                          last_space = buf.rfind(" ")
   196                          if last_space > 20:
   197                              out.append(buf[:last_space].strip())
   198                              buf = buf[last_space+1:]
   199  
   200                      for s in out:
   201                          if self._stop.is_set(): break
   202                          if on_first_speak and not first_spoken:
   203                              first_spoken = True
   204                              try: on_first_speak()
   205                              except Exception: pass
   206                          wav = self._synth_to_wav(s, lang)
   207                          try:
   208                              self._play_wav_blocking(wav)
   209                          finally:
   210                              try: os.remove(wav)
   211                              except: pass
   212                          if self.sil_ms > 0:
   213                              self._sleep_ms(self.sil_ms)
   214  
   215                  # finalizeazÄƒ ce-a rÄƒmas
   216                  tail = buf.strip()
   217                  if (not self._stop.is_set()) and tail:
   218                      if on_first_speak and not first_spoken:
   219                          first_spoken = True
   220                          try: on_first_speak()
   221                          except Exception: pass
   222                      wav = self._synth_to_wav(tail, lang)
   223                      try:
   224                          self._play_wav_blocking(wav)
   225                      finally:
   226                          try: os.remove(wav)
   227                          except: pass
   228              except Exception as e:
   229                  self.log.error(f"Piper stream error: {e}")
   230              finally:
   231                  self._speaking.clear()
   232                  if on_done:
   233                      try: on_done()
   234                      except Exception: pass
   235  
   236          self.stop()
   237          self._stop.clear()
   238          self._speak_th = threading.Thread(target=worker, daemon=True)
   239          self._speak_th.start()
   240          return self._speaking
   241  
   242      def stop(self):
   243          with self._lock:
   244              self._stop.set()
   245              try: sd.stop()
   246              except Exception: pass
   247          self._speaking.clear()

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/utils/__init__.py =====

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/utils/debug_speech.py =====
     1  from __future__ import annotations
     2  from pathlib import Path
     3  from datetime import datetime
     4  from typing import Iterable, Generator, Optional
     5  
     6  class DebugSpeech:
     7      """
     8      ColecteazÄƒ ce intrÄƒ/iese Ã®n pipeline:
     9      - asr.txt          -> ce a auzit ASR
    10      - llm_stream.txt   -> token cu token (pe mÄƒsurÄƒ ce vin)
    11      - spoken_text.txt  -> tot textul trimis spre TTS (concat)
    12      - session.log      -> timpi, praguri, evenimente
    13      """
    14      def __init__(self, base_dir: Path, lang: str, logger):
    15          self.base_dir = Path(base_dir)
    16          self.base_dir.mkdir(parents=True, exist_ok=True)
    17          self.lang = lang
    18          self.logger = logger
    19          self._buf = []
    20          self._ttft_ms: Optional[float] = None
    21          self._started_tts = False
    22          self._closed = False
    23  
    24          self._asr_f = (self.base_dir / "00_asr.txt").open("w", encoding="utf-8")
    25          self._llm_f = (self.base_dir / "10_llm_stream.txt").open("w", encoding="utf-8")
    26          self._spoken_f = (self.base_dir / "20_spoken_text.txt").open("w", encoding="utf-8")
    27          self._sess_f = (self.base_dir / "session.log").open("a", encoding="utf-8")
    28  
    29          self._log(f"# Session {datetime.now().isoformat(timespec='seconds')} lang={lang}")
    30  
    31      def _log(self, msg: str):
    32          if self._closed:
    33              return
    34          self._sess_f.write(msg.rstrip() + "\n")
    35          self._sess_f.flush()
    36          self.logger.debug(msg)
    37  
    38      def write_asr(self, text: str):
    39          if self._closed:
    40              return
    41          self._asr_f.write((text or "").rstrip() + "\n")
    42          self._asr_f.flush()
    43          self._log(f"[ASR] {text}")
    44  
    45      def on_first_token(self, ttft_seconds: float):
    46          self._ttft_ms = ttft_seconds * 1000.0
    47          self._log(f"[LLM] TTFT={self._ttft_ms:.1f} ms")
    48  
    49      def on_token(self, tok: str):
    50          if not tok or self._closed:
    51              return
    52          self._buf.append(tok)
    53          self._llm_f.write(tok)
    54          self._llm_f.flush()
    55  
    56      def on_tts_start(self):
    57          if self._closed:
    58              return
    59          self._started_tts = True
    60          self._log("[TTS] start")
    61  
    62      def on_tts_end(self):
    63          if self._closed:
    64              return
    65          self._log("[TTS] end")
    66  
    67      def tee(self, gen: Iterable[str]) -> Generator[str, None, None]:
    68          """
    69          ÃmpacheteazÄƒ generatorul de tokeni: logheazÄƒ È™i relay-uieÈ™te mai departe.
    70          """
    71          first = True
    72          import time
    73          t0 = time.perf_counter()
    74          for tok in gen:
    75              if first:
    76                  first = False
    77                  ttft = time.perf_counter() - t0
    78                  # dacÄƒ nu vine din wrap_stream_for_first_token, mÄƒcar aproximÄƒm aici
    79                  if self._ttft_ms is None:
    80                      self.on_first_token(ttft)
    81              self.on_token(tok)
    82              yield tok
    83  
    84      def finish(self):
    85          if self._closed:
    86              return
    87          text = "".join(self._buf)
    88          self._spoken_f.write(text)
    89          self._spoken_f.flush()
    90          self._log(f"[SPOKEN] {len(text)} chars")
    91          # close files
    92          for f in (self._asr_f, self._llm_f, self._spoken_f, self._sess_f):
    93              try:
    94                  f.close()
    95              except Exception:
    96                  pass
    97          self._closed = True

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/utils/textnorm.py =====
     1  import re
     2  import unicodedata
     3  
     4  _ROM_DIACRITICS = str.maketrans({
     5      "Äƒ": "a", "Ã¢": "a", "Ã®": "i", "ÅŸ": "s", "È™": "s", "Å£": "t", "È›": "t",
     6      "Ä‚": "a", "Ã‚": "a", "Ã": "i", "Å": "s", "È˜": "s", "Å¢": "t", "Èš": "t",
     7  })
     8  
     9  def normalize_text(s: str) -> str:
    10      if not s:
    11          return ""
    12      s = unicodedata.normalize("NFKC", s)
    13      s = s.translate(_ROM_DIACRITICS)
    14      s = s.lower()
    15      s = re.sub(r"[^a-z0-9\s]", " ", s)
    16      s = re.sub(r"\s+", " ", s).strip()
    17      return s

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/src/wake/porcupine_engine.py =====
     1  from __future__ import annotations
     2  from typing import List, Optional
     3  import os
     4  import pvporcupine
     5  import soundfile as sf
     6  import numpy as np
     7  
     8  class PorcupineWake:
     9      def __init__(
    10          self,
    11          access_key: str,
    12          keyword_paths: Optional[List[str]] = None,
    13          keywords: Optional[List[str]] = None,
    14          sensitivities: Optional[List[float]] = None,
    15          logger=None,
    16      ):
    17          self.log = logger
    18          ak = (access_key or "").strip() or os.getenv("PICOVOICE_ACCESS_KEY", "")
    19          if not ak:
    20              raise RuntimeError("Porcupine access_key lipseÈ™te (seteazÄƒ wake.porcupine.access_key sau env PICOVOICE_ACCESS_KEY).")
    21  
    22          kws = keyword_paths or None
    23          kbn = keywords or None
    24          if not (kws or kbn):
    25              raise RuntimeError("Porcupine: configureazÄƒ fie 'keyword_paths', fie 'keywords' Ã®n configs/wake.yaml.")
    26  
    27          sens = sensitivities or [0.5] * (len(kws or kbn))
    28          self.ppn = pvporcupine.create(
    29              access_key=ak,
    30              keyword_paths=kws,
    31              keywords=kbn,
    32              sensitivities=sens,
    33          )
    34          self.frame_len = self.ppn.frame_length
    35          self.sr = self.ppn.sample_rate
    36  
    37          if kws:
    38              self.labels = [os.path.splitext(os.path.basename(p))[0] for p in kws]
    39          else:
    40              self.labels = list(kbn)
    41  
    42      def close(self):
    43          try:
    44              if self.ppn:
    45                  self.ppn.delete()
    46          except Exception:
    47              pass
    48  
    49      def detect_in_wav(self, wav_path: str) -> Optional[str]:
    50          try:
    51              audio, sr = sf.read(wav_path, dtype="int16", always_2d=False)
    52          except Exception as e:
    53              if self.log: self.log.error(f"Porcupine: nu pot citi WAV: {e}")
    54              return None
    55  
    56          if sr != self.sr:
    57              if self.log: self.log.warning(f"Porcupine cere {self.sr} Hz, dar WAV are {sr} Hz. SeteazÄƒ audio.sample_rate={self.sr}.")
    58              return None
    59  
    60          if audio.ndim == 2:
    61              audio = audio.mean(axis=1).astype("int16")
    62  
    63          n = len(audio) - (len(audio) % self.frame_len)
    64          for i in range(0, n, self.frame_len):
    65              frame = np.array(audio[i:i+self.frame_len], dtype=np.int16)
    66              res = self.ppn.process(frame)
    67              if res >= 0:
    68                  idx = int(res)
    69                  return self.labels[idx] if 0 <= idx < len(self.labels) else "wake"
    70          return None

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/tools/export_code.py =====
     1  #!/usr/bin/env python3
     2  import sys, os, argparse
     3  
     4  DEFAULT_EXTS = {".py",".js",".ts",".jsx",".tsx",".json",".md",".yml",".yaml",
     5                  ".sh",".txt",".ini",".cfg",".toml",".html",".css"}
     6  DEFAULT_EXCLUDE_DIRS = {".venv",".git","node_modules","__pycache__","dist","build",".idea",".vscode"}
     7  
     8  def should_skip_dir(path):
     9      parts = set(os.path.normpath(path).split(os.sep))
    10      return any(d in parts for d in DEFAULT_EXCLUDE_DIRS)
    11  
    12  def iter_files(root, exts):
    13      for dirpath, dirnames, filenames in os.walk(root):
    14          # filtreazÄƒ directoarele excluse
    15          dirnames[:] = [d for d in dirnames if d not in DEFAULT_EXCLUDE_DIRS]
    16          if should_skip_dir(dirpath): 
    17              continue
    18          for fn in filenames:
    19              _, ext = os.path.splitext(fn)
    20              if ext.lower() in exts:
    21                  yield os.path.join(dirpath, fn)
    22  
    23  def dump_file(fp, path, max_bytes=None):
    24      print(f"===== FILE: {path} =====", file=fp)
    25      try:
    26          with open(path, "r", encoding="utf-8", errors="replace") as f:
    27              for i, line in enumerate(f, start=1):
    28                  if max_bytes and fp.tell() > max_bytes:
    29                      print(f"[TRUNCATED OUTPUT: reached {max_bytes} bytes]", file=fp)
    30                      return
    31                  fp.write(f"{i:6d}  {line}")
    32      except Exception as e:
    33          print(f"[ERROR reading {path}: {e}]", file=fp)
    34      fp.write("\n")
    35  
    36  def main():
    37      ap = argparse.ArgumentParser(description="ExportÄƒ codul Ã®ntr-un singur fiÈ™ier text cu numerotare pe linii.")
    38      ap.add_argument("--root", default=".", help="RÄƒdÄƒcina proiectului (default: .)")
    39      ap.add_argument("--out", default="code_dump.txt", help="FiÈ™ierul de ieÈ™ire (default: code_dump.txt)")
    40      ap.add_argument("--max-bytes", type=int, default=None, help="Limita opÈ›ionalÄƒ de dimensiune a ieÈ™irii")
    41      ap.add_argument("--ext", nargs="*", default=sorted(DEFAULT_EXTS),
    42                      help="Extensii incluse (default: set comun pentru cod)")
    43      args = ap.parse_args()
    44  
    45      root = os.path.abspath(args.root)
    46      files = sorted(iter_files(root, set(e.lower() if e.startswith(".") else "."+e.lower() for e in args.ext)))
    47  
    48      with open(args.out, "w", encoding="utf-8", errors="replace") as fp:
    49          print(f"# CODE DUMP FROM: {root}\n# FILE COUNT: {len(files)}\n", file=fp)
    50          print("# MANIFEST:", file=fp)
    51          for p in files:
    52              print(p, file=fp)
    53          print("\n# CONTENT:\n", file=fp)
    54          for p in files:
    55              dump_file(fp, p, max_bytes=args.max_bytes)
    56  
    57      print(f"Am scris {len(files)} fiÈ™iere Ã®n {args.out}")
    58  
    59  if __name__ == "__main__":
    60      main()

===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/voices/en_US-amy-medium.onnx.json =====
     1  {
     2    "audio": {
     3      "sample_rate": 22050,
     4      "quality": "medium"
     5    },
     6    "espeak": {
     7      "voice": "en-us"
     8    },
     9    "inference": {
    10      "noise_scale": 0.667,
    11      "length_scale": 1,
    12      "noise_w": 0.8
    13    },
    14    "phoneme_type": "espeak",
    15    "phoneme_map": {},
    16    "phoneme_id_map": {
    17      "_": [
    18        0
    19      ],
    20      "^": [
    21        1
    22      ],
    23      "$": [
    24        2
    25      ],
    26      " ": [
    27        3
    28      ],
    29      "!": [
    30        4
    31      ],
    32      "'": [
    33        5
    34      ],
    35      "(": [
    36        6
    37      ],
    38      ")": [
    39        7
    40      ],
    41      ",": [
    42        8
    43      ],
    44      "-": [
    45        9
    46      ],
    47      ".": [
    48        10
    49      ],
    50      ":": [
    51        11
    52      ],
    53      ";": [
    54        12
    55      ],
    56      "?": [
    57        13
    58      ],
    59      "a": [
    60        14
    61      ],
    62      "b": [
    63        15
    64      ],
    65      "c": [
    66        16
    67      ],
    68      "d": [
    69        17
    70      ],
    71      "e": [
    72        18
    73      ],
    74      "f": [
    75        19
    76      ],
    77      "h": [
    78        20
    79      ],
    80      "i": [
    81        21
    82      ],
    83      "j": [
    84        22
    85      ],
    86      "k": [
    87        23
    88      ],
    89      "l": [
    90        24
    91      ],
    92      "m": [
    93        25
    94      ],
    95      "n": [
    96        26
    97      ],
    98      "o": [
    99        27
   100      ],
   101      "p": [
   102        28
   103      ],
   104      "q": [
   105        29
   106      ],
   107      "r": [
   108        30
   109      ],
   110      "s": [
   111        31
   112      ],
   113      "t": [
   114        32
   115      ],
   116      "u": [
   117        33
   118      ],
   119      "v": [
   120        34
   121      ],
   122      "w": [
   123        35
   124      ],
   125      "x": [
   126        36
   127      ],
   128      "y": [
   129        37
   130      ],
   131      "z": [
   132        38
   133      ],
   134      "Ã¦": [
   135        39
   136      ],
   137      "Ã§": [
   138        40
   139      ],
   140      "Ã°": [
   141        41
   142      ],
   143      "Ã¸": [
   144        42
   145      ],
   146      "Ä§": [
   147        43
   148      ],
   149      "Å‹": [
   150        44
   151      ],
   152      "Å“": [
   153        45
   154      ],
   155      "Ç€": [
   156        46
   157      ],
   158      "Ç": [
   159        47
   160      ],
   161      "Ç‚": [
   162        48
   163      ],
   164      "Çƒ": [
   165        49
   166      ],
   167      "É": [
   168        50
   169      ],
   170      "É‘": [
   171        51
   172      ],
   173      "É’": [
   174        52
   175      ],
   176      "É“": [
   177        53
   178      ],
   179      "É”": [
   180        54
   181      ],
   182      "É•": [
   183        55
   184      ],
   185      "É–": [
   186        56
   187      ],
   188      "É—": [
   189        57
   190      ],
   191      "É˜": [
   192        58
   193      ],
   194      "É™": [
   195        59
   196      ],
   197      "Éš": [
   198        60
   199      ],
   200      "É›": [
   201        61
   202      ],
   203      "Éœ": [
   204        62
   205      ],
   206      "É": [
   207        63
   208      ],
   209      "ÉŸ": [
   210        64
   211      ],
   212      "É ": [
   213        65
   214      ],
   215      "É¡": [
   216        66
   217      ],
   218      "É¢": [
   219        67
   220      ],
   221      "É£": [
   222        68
   223      ],
   224      "É¤": [
   225        69
   226      ],
   227      "É¥": [
   228        70
   229      ],
   230      "É¦": [
   231        71
   232      ],
   233      "É§": [
   234        72
   235      ],
   236      "É¨": [
   237        73
   238      ],
   239      "Éª": [
   240        74
   241      ],
   242      "É«": [
   243        75
   244      ],
   245      "É¬": [
   246        76
   247      ],
   248      "É­": [
   249        77
   250      ],
   251      "É®": [
   252        78
   253      ],
   254      "É¯": [
   255        79
   256      ],
   257      "É°": [
   258        80
   259      ],
   260      "É±": [
   261        81
   262      ],
   263      "É²": [
   264        82
   265      ],
   266      "É³": [
   267        83
   268      ],
   269      "É´": [
   270        84
   271      ],
   272      "Éµ": [
   273        85
   274      ],
   275      "É¶": [
   276        86
   277      ],
   278      "É¸": [
   279        87
   280      ],
   281      "É¹": [
   282        88
   283      ],
   284      "Éº": [
   285        89
   286      ],
   287      "É»": [
   288        90
   289      ],
   290      "É½": [
   291        91
   292      ],
   293      "É¾": [
   294        92
   295      ],
   296      "Ê€": [
   297        93
   298      ],
   299      "Ê": [
   300        94
   301      ],
   302      "Ê‚": [
   303        95
   304      ],
   305      "Êƒ": [
   306        96
   307      ],
   308      "Ê„": [
   309        97
   310      ],
   311      "Êˆ": [
   312        98
   313      ],
   314      "Ê‰": [
   315        99
   316      ],
   317      "ÊŠ": [
   318        100
   319      ],
   320      "Ê‹": [
   321        101
   322      ],
   323      "ÊŒ": [
   324        102
   325      ],
   326      "Ê": [
   327        103
   328      ],
   329      "Ê": [
   330        104
   331      ],
   332      "Ê": [
   333        105
   334      ],
   335      "Ê": [
   336        106
   337      ],
   338      "Ê‘": [
   339        107
   340      ],
   341      "Ê’": [
   342        108
   343      ],
   344      "Ê”": [
   345        109
   346      ],
   347      "Ê•": [
   348        110
   349      ],
   350      "Ê˜": [
   351        111
   352      ],
   353      "Ê™": [
   354        112
   355      ],
   356      "Ê›": [
   357        113
   358      ],
   359      "Êœ": [
   360        114
   361      ],
   362      "Ê": [
   363        115
   364      ],
   365      "ÊŸ": [
   366        116
   367      ],
   368      "Ê¡": [
   369        117
   370      ],
   371      "Ê¢": [
   372        118
   373      ],
   374      "Ê²": [
   375        119
   376      ],
   377      "Ëˆ": [
   378        120
   379      ],
   380      "ËŒ": [
   381        121
   382      ],
   383      "Ë": [
   384        122
   385      ],
   386      "Ë‘": [
   387        123
   388      ],
   389      "Ë": [
   390        124
   391      ],
   392      "Î²": [
   393        125
   394      ],
   395      "Î¸": [
   396        126
   397      ],
   398      "Ï‡": [
   399        127
   400      ],
   401      "áµ»": [
   402        128
   403      ],
   404      "â±±": [
   405        129
   406      ],
   407      "0": [
   408        130
   409      ],
   410      "1": [
   411        131
   412      ],
   413      "2": [
   414        132
   415      ],
   416      "3": [
   417        133
   418      ],
   419      "4": [
   420        134
   421      ],
   422      "5": [
   423        135
   424      ],
   425      "6": [
   426        136
   427      ],
   428      "7": [
   429        137
   430      ],
   431      "8": [
   432        138
   433      ],
   434      "9": [
   435        139
   436      ],
   437      "Ì§": [
   438        140
   439      ],
   440      "Ìƒ": [
   441        141
   442      ],
   443      "Ìª": [
   444        142
   445      ],
   446      "Ì¯": [
   447        143
   448      ],
   449      "Ì©": [
   450        144
   451      ],
   452      "Ê°": [
   453        145
   454      ],
   455      "Ë¤": [
   456        146
   457      ],
   458      "Îµ": [
   459        147
   460      ],
   461      "â†“": [
   462        148
   463      ],
   464      "#": [
   465        149
   466      ],
   467      "\"": [
   468        150
   469      ],
   470      "â†‘": [
   471        151
   472      ],
   473      "Ìº": [
   474        152
   475      ],
   476      "Ì»": [
   477        153
   478      ]
   479    },
   480    "num_symbols": 256,
   481    "num_speakers": 1,
   482    "speaker_id_map": {},
   483    "piper_version": "1.0.0",
   484    "language": {
   485      "code": "en_US",
   486      "family": "en",
   487      "region": "US",
   488      "name_native": "English",
   489      "name_english": "English",
   490      "country_english": "United States"
   491    },
   492    "dataset": "amy"
   493  }
===== FILE: /home/delia/Conversational_Robot/Conversational_Bot/voices/ro_RO-mihai-medium.onnx.json =====
     1  {
     2    "piper_version": "1.0.0",
     3    "audio": {
     4      "sample_rate": 22050,
     5      "quality": "medium"
     6    },
     7    "espeak": {
     8      "voice": "ro"
     9    },
    10    "inference": {
    11      "noise_scale": 0.667,
    12      "length_scale": 1,
    13      "noise_w": 0.8
    14    },
    15    "phoneme_type": "espeak",
    16    "phoneme_map": {},
    17    "phoneme_id_map": {
    18      "_": [
    19        0
    20      ],
    21      "^": [
    22        1
    23      ],
    24      "$": [
    25        2
    26      ],
    27      " ": [
    28        3
    29      ],
    30      "!": [
    31        4
    32      ],
    33      "'": [
    34        5
    35      ],
    36      "(": [
    37        6
    38      ],
    39      ")": [
    40        7
    41      ],
    42      ",": [
    43        8
    44      ],
    45      "-": [
    46        9
    47      ],
    48      ".": [
    49        10
    50      ],
    51      ":": [
    52        11
    53      ],
    54      ";": [
    55        12
    56      ],
    57      "?": [
    58        13
    59      ],
    60      "a": [
    61        14
    62      ],
    63      "b": [
    64        15
    65      ],
    66      "c": [
    67        16
    68      ],
    69      "d": [
    70        17
    71      ],
    72      "e": [
    73        18
    74      ],
    75      "f": [
    76        19
    77      ],
    78      "h": [
    79        20
    80      ],
    81      "i": [
    82        21
    83      ],
    84      "j": [
    85        22
    86      ],
    87      "k": [
    88        23
    89      ],
    90      "l": [
    91        24
    92      ],
    93      "m": [
    94        25
    95      ],
    96      "n": [
    97        26
    98      ],
    99      "o": [
   100        27
   101      ],
   102      "p": [
   103        28
   104      ],
   105      "q": [
   106        29
   107      ],
   108      "r": [
   109        30
   110      ],
   111      "s": [
   112        31
   113      ],
   114      "t": [
   115        32
   116      ],
   117      "u": [
   118        33
   119      ],
   120      "v": [
   121        34
   122      ],
   123      "w": [
   124        35
   125      ],
   126      "x": [
   127        36
   128      ],
   129      "y": [
   130        37
   131      ],
   132      "z": [
   133        38
   134      ],
   135      "Ã¦": [
   136        39
   137      ],
   138      "Ã§": [
   139        40
   140      ],
   141      "Ã°": [
   142        41
   143      ],
   144      "Ã¸": [
   145        42
   146      ],
   147      "Ä§": [
   148        43
   149      ],
   150      "Å‹": [
   151        44
   152      ],
   153      "Å“": [
   154        45
   155      ],
   156      "Ç€": [
   157        46
   158      ],
   159      "Ç": [
   160        47
   161      ],
   162      "Ç‚": [
   163        48
   164      ],
   165      "Çƒ": [
   166        49
   167      ],
   168      "É": [
   169        50
   170      ],
   171      "É‘": [
   172        51
   173      ],
   174      "É’": [
   175        52
   176      ],
   177      "É“": [
   178        53
   179      ],
   180      "É”": [
   181        54
   182      ],
   183      "É•": [
   184        55
   185      ],
   186      "É–": [
   187        56
   188      ],
   189      "É—": [
   190        57
   191      ],
   192      "É˜": [
   193        58
   194      ],
   195      "É™": [
   196        59
   197      ],
   198      "Éš": [
   199        60
   200      ],
   201      "É›": [
   202        61
   203      ],
   204      "Éœ": [
   205        62
   206      ],
   207      "É": [
   208        63
   209      ],
   210      "ÉŸ": [
   211        64
   212      ],
   213      "É ": [
   214        65
   215      ],
   216      "É¡": [
   217        66
   218      ],
   219      "É¢": [
   220        67
   221      ],
   222      "É£": [
   223        68
   224      ],
   225      "É¤": [
   226        69
   227      ],
   228      "É¥": [
   229        70
   230      ],
   231      "É¦": [
   232        71
   233      ],
   234      "É§": [
   235        72
   236      ],
   237      "É¨": [
   238        73
   239      ],
   240      "Éª": [
   241        74
   242      ],
   243      "É«": [
   244        75
   245      ],
   246      "É¬": [
   247        76
   248      ],
   249      "É­": [
   250        77
   251      ],
   252      "É®": [
   253        78
   254      ],
   255      "É¯": [
   256        79
   257      ],
   258      "É°": [
   259        80
   260      ],
   261      "É±": [
   262        81
   263      ],
   264      "É²": [
   265        82
   266      ],
   267      "É³": [
   268        83
   269      ],
   270      "É´": [
   271        84
   272      ],
   273      "Éµ": [
   274        85
   275      ],
   276      "É¶": [
   277        86
   278      ],
   279      "É¸": [
   280        87
   281      ],
   282      "É¹": [
   283        88
   284      ],
   285      "Éº": [
   286        89
   287      ],
   288      "É»": [
   289        90
   290      ],
   291      "É½": [
   292        91
   293      ],
   294      "É¾": [
   295        92
   296      ],
   297      "Ê€": [
   298        93
   299      ],
   300      "Ê": [
   301        94
   302      ],
   303      "Ê‚": [
   304        95
   305      ],
   306      "Êƒ": [
   307        96
   308      ],
   309      "Ê„": [
   310        97
   311      ],
   312      "Êˆ": [
   313        98
   314      ],
   315      "Ê‰": [
   316        99
   317      ],
   318      "ÊŠ": [
   319        100
   320      ],
   321      "Ê‹": [
   322        101
   323      ],
   324      "ÊŒ": [
   325        102
   326      ],
   327      "Ê": [
   328        103
   329      ],
   330      "Ê": [
   331        104
   332      ],
   333      "Ê": [
   334        105
   335      ],
   336      "Ê": [
   337        106
   338      ],
   339      "Ê‘": [
   340        107
   341      ],
   342      "Ê’": [
   343        108
   344      ],
   345      "Ê”": [
   346        109
   347      ],
   348      "Ê•": [
   349        110
   350      ],
   351      "Ê˜": [
   352        111
   353      ],
   354      "Ê™": [
   355        112
   356      ],
   357      "Ê›": [
   358        113
   359      ],
   360      "Êœ": [
   361        114
   362      ],
   363      "Ê": [
   364        115
   365      ],
   366      "ÊŸ": [
   367        116
   368      ],
   369      "Ê¡": [
   370        117
   371      ],
   372      "Ê¢": [
   373        118
   374      ],
   375      "Ê²": [
   376        119
   377      ],
   378      "Ëˆ": [
   379        120
   380      ],
   381      "ËŒ": [
   382        121
   383      ],
   384      "Ë": [
   385        122
   386      ],
   387      "Ë‘": [
   388        123
   389      ],
   390      "Ë": [
   391        124
   392      ],
   393      "Î²": [
   394        125
   395      ],
   396      "Î¸": [
   397        126
   398      ],
   399      "Ï‡": [
   400        127
   401      ],
   402      "áµ»": [
   403        128
   404      ],
   405      "â±±": [
   406        129
   407      ],
   408      "0": [
   409        130
   410      ],
   411      "1": [
   412        131
   413      ],
   414      "2": [
   415        132
   416      ],
   417      "3": [
   418        133
   419      ],
   420      "4": [
   421        134
   422      ],
   423      "5": [
   424        135
   425      ],
   426      "6": [
   427        136
   428      ],
   429      "7": [
   430        137
   431      ],
   432      "8": [
   433        138
   434      ],
   435      "9": [
   436        139
   437      ],
   438      "Ì§": [
   439        140
   440      ],
   441      "Ìƒ": [
   442        141
   443      ],
   444      "Ìª": [
   445        142
   446      ],
   447      "Ì¯": [
   448        143
   449      ],
   450      "Ì©": [
   451        144
   452      ],
   453      "Ê°": [
   454        145
   455      ],
   456      "Ë¤": [
   457        146
   458      ],
   459      "Îµ": [
   460        147
   461      ],
   462      "â†“": [
   463        148
   464      ],
   465      "#": [
   466        149
   467      ],
   468      "\"": [
   469        150
   470      ],
   471      "â†‘": [
   472        151
   473      ],
   474      "Ìº": [
   475        152
   476      ],
   477      "Ì»": [
   478        153
   479      ]
   480    },
   481    "num_symbols": 256,
   482    "num_speakers": 1,
   483    "speaker_id_map": {},
   484    "language": {
   485      "code": "ro_RO",
   486      "family": "ro",
   487      "region": "RO",
   488      "name_native": "RomÃ¢nÄƒ",
   489      "name_english": "Romanian",
   490      "country_english": "Romania"
   491    },
   492    "dataset": "mihai"
   493  }
